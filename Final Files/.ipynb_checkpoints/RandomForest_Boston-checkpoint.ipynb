{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjzGopb_YcKR"
   },
   "source": [
    "# Application of Bootstrap samples in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZSCtDI6YcKT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2Y1Z1DoYcKZ"
   },
   "source": [
    " <li> Load the boston house dataset </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wBWRNKCDYcKb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           0     1      2    3      4      5     6       7    8      9    10  \\\n",
       " 0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       " 1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       " 2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       " 3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       " 4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       " ..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       " 501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
       " 502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
       " 503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
       " 504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
       " 505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
       " \n",
       "          11    12     y  \n",
       " 0    396.90  4.98  24.0  \n",
       " 1    396.90  9.14  21.6  \n",
       " 2    392.83  4.03  34.7  \n",
       " 3    394.63  2.94  33.4  \n",
       " 4    396.90  5.33  36.2  \n",
       " ..      ...   ...   ...  \n",
       " 501  391.99  9.67  22.4  \n",
       " 502  396.90  9.08  20.6  \n",
       " 503  396.90  5.64  23.9  \n",
       " 504  393.45  6.48  22.0  \n",
       " 505  396.90  7.88  11.9  \n",
       " \n",
       " [506 rows x 14 columns],\n",
       " (506, 14))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable\n",
    "df = pd.DataFrame(x)\n",
    "df['y'] = y\n",
    "df,df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JJ_FwP7xYcKg"
   },
   "source": [
    "### Task: 1\n",
    "<font color='red'><b>Step 1 Creating samples: </b></font> Randomly create 30 samples from the whole boston data points.\n",
    "<ol>\n",
    "<li>Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points</li>\n",
    "<li>Ex: For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly consider we have selected [4, 5, 7, 8, 9, 3] now we will replciate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]</li>\n",
    "<li> we create 30 samples like this </li>\n",
    "<li> Note that as a part of the Bagging when you are taking the random samples make sure each of the sample will have                different set of columns</li>\n",
    "<li> Ex: assume we have 10 columns for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample [7, 9, 1, 4, 5, 6, 2] and so on...</li>\n",
    "<li> Make sure each sample will have atleast 3 feautres/columns/attributes</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 2 Building High Variance Models on each of the sample and finding train MSE value:</b></font> Build a DecisionTreeRegressor on each of the sample.\n",
    "<ol><li>Build a regression trees on each of 30 samples.</li>\n",
    "<li>computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li> predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})$.</li>\n",
    "</ol>\n",
    "\n",
    "<font color='red'><b>Step 3 Calculating the OOB score :</b></font>\n",
    "<ol>\n",
    "<li>Computed the predicted values of each data point(506 data points) in your corpus.</li>\n",
    "<li>Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.</li>\n",
    "<li>Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})$.</li>\n",
    "</ol>\n",
    "\n",
    "### Task: 2\n",
    "<pre>\n",
    "<font color='red'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
    "<ol>\n",
    "<li> Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
    "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
    "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
    "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
    "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
    "</ol>\n",
    "</pre>\n",
    "### Task: 3\n",
    "<pre>\n",
    "<font color='red'><b>Given a single query point predict the price of house.</b></font>\n",
    "\n",
    "<li>Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] Predict the house price for this point as mentioned in the step 2 of Task 1. </li>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x,t_x,tr_y,t_y = train_test_split(df.iloc[:,:-1],df.iloc[:,-1],train_size=303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.38735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>5.613</td>\n",
       "      <td>95.6</td>\n",
       "      <td>1.7572</td>\n",
       "      <td>2.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>359.29</td>\n",
       "      <td>27.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.59005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>6.372</td>\n",
       "      <td>97.9</td>\n",
       "      <td>2.3274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>385.76</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.02899</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>6.939</td>\n",
       "      <td>34.5</td>\n",
       "      <td>8.7921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>389.85</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.07978</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>6.482</td>\n",
       "      <td>32.1</td>\n",
       "      <td>4.1403</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>5.44114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.655</td>\n",
       "      <td>98.2</td>\n",
       "      <td>2.3552</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>355.29</td>\n",
       "      <td>17.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.03510</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4161</td>\n",
       "      <td>7.853</td>\n",
       "      <td>33.2</td>\n",
       "      <td>5.1180</td>\n",
       "      <td>4.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>392.78</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.06127</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>6.826</td>\n",
       "      <td>27.6</td>\n",
       "      <td>4.8628</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>393.45</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.01870</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>6.516</td>\n",
       "      <td>27.7</td>\n",
       "      <td>8.5353</td>\n",
       "      <td>4.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>392.43</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2    3       4      5     6       7     8      9   \\\n",
       "126  0.38735   0.0  25.65  0.0  0.5810  5.613  95.6  1.7572   2.0  188.0   \n",
       "132  0.59005   0.0  21.89  0.0  0.6240  6.372  97.9  2.3274   4.0  437.0   \n",
       "349  0.02899  40.0   1.25  0.0  0.4290  6.939  34.5  8.7921   1.0  335.0   \n",
       "278  0.07978  40.0   6.41  0.0  0.4470  6.482  32.1  4.1403   4.0  254.0   \n",
       "451  5.44114   0.0  18.10  0.0  0.7130  6.655  98.2  2.3552  24.0  666.0   \n",
       "..       ...   ...    ...  ...     ...    ...   ...     ...   ...    ...   \n",
       "0    0.00632  18.0   2.31  0.0  0.5380  6.575  65.2  4.0900   1.0  296.0   \n",
       "500  0.22438   0.0   9.69  0.0  0.5850  6.027  79.7  2.4982   6.0  391.0   \n",
       "203  0.03510  95.0   2.68  0.0  0.4161  7.853  33.2  5.1180   4.0  224.0   \n",
       "277  0.06127  40.0   6.41  1.0  0.4470  6.826  27.6  4.8628   4.0  254.0   \n",
       "347  0.01870  85.0   4.15  0.0  0.4290  6.516  27.7  8.5353   4.0  351.0   \n",
       "\n",
       "       10      11     12  \n",
       "126  19.1  359.29  27.26  \n",
       "132  21.2  385.76  11.12  \n",
       "349  19.7  389.85   5.89  \n",
       "278  17.6  396.90   7.19  \n",
       "451  20.2  355.29  17.73  \n",
       "..    ...     ...    ...  \n",
       "0    15.3  396.90   4.98  \n",
       "500  19.2  396.90  14.33  \n",
       "203  14.7  392.78   3.81  \n",
       "277  17.6  393.45   4.16  \n",
       "347  17.9  392.43   6.36  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 72.20it/s]\n",
      "506it [00:05, 98.51it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.1838841440186907], [0.007076970434703175])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = []\n",
    "oob =[]\n",
    "for x in range(1):\n",
    "    a_clf={}\n",
    "    index = dict()\n",
    "    pred_plus = np.zeros(506)\n",
    "    for i in tqdm(range(1,31)):\n",
    "        c = random.randint(4,10)\n",
    "        df2 = df.iloc[:,:-1].sample(n=c,axis=1)\n",
    "        df2 = df2.reindex(sorted(df2.columns), axis=1)\n",
    "        df2['y'] = df['y']\n",
    "        df3 = df2.sample(n=303).sort_index()\n",
    "        index[i] ={\n",
    "            'row':list(df3.index),\n",
    "            'col':list(df2.columns)\n",
    "        }\n",
    "        df3 = pd.concat([df3,df3.sample(n=203)]).sort_index()\n",
    "        # gs_clf = GridSearchCV(estimator = DecisionTreeRegressor(),param_grid ={'max_depth':[5,10,15,20,30],'min_samples_split':[10,20,30,40,50]})\n",
    "        clf= DecisionTreeRegressor(max_depth=100,min_samples_split=3) ## Taking high variance models as we are here to imitate the Bagging-RandomForest, which reduces the variance of the models.\n",
    "        # gs_clf.fit(df3.iloc[:,:-1],df3.iloc[:,-1])\n",
    "        clf.fit(df3.iloc[:,:-1],df3.iloc[:,-1])\n",
    "        # clf = gs_clf.best_estimator_\n",
    "        a_clf[i] = clf\n",
    "        pred_plus = pred_plus + clf.predict(df2.iloc[:,:-1])\n",
    "    MSe = sum((pred_plus/30-df2.iloc[:,-1])**2)/506\n",
    "\n",
    "    # OOB scor calculation\n",
    "    oob_pred =[]\n",
    "    pl =[]\n",
    "    for ind,dat in tqdm(df.iterrows()):\n",
    "        pred_val = []\n",
    "        for i in range(1,31):\n",
    "            if ind not in index[i]['row']:\n",
    "                val = a_clf[i].predict(dat[index[i]['col']].iloc[:-1].to_numpy().reshape(1,-1))\n",
    "                pred_val.append(val[0])\n",
    "        pl.append(len(pred_val))\n",
    "        oob_pred.append(mean(pred_val))\n",
    "    OOb = sum(oob_pred-df['y'])/506\n",
    "\n",
    "    mse.append(MSe)\n",
    "    oob.append(OOb)\n",
    "mse,oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.1838841440186907], [0.007076970434703175])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse,oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.811666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n",
    "x_q = pd.Series(xq)\n",
    "prediction = []\n",
    "for i in range(1,31):\n",
    "    prediction.append(a_clf[i].predict(x_q.iloc[index[i]['col'][:-1]].to_numpy().reshape(1,-1))[0])\n",
    "mean(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bootstrap_Random_Forest_instructions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml1': conda)",
   "language": "python",
   "name": "python37764bitml1condab1e7a9cc0a4b4da2aa1261f0c90e368a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
