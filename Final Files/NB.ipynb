{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitml1condab1e7a9cc0a4b4da2aa1261f0c90e368a",
   "display_name": "Python 3.7.7 64-bit ('ml1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "- ### Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from statistics import mean\n",
    "from scipy.sparse import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "source": [
    "- ### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "per_data = pd.read_csv('../datafiles/doners/final_data.csv')\n",
    "per_data.info(),per_data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Multinomial NB does not take negative values as input, we need to drop 'std_price'\n",
    "per_data.drop(['std_price'],axis=1,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_data.head(5)"
   ]
  },
  {
   "source": [
    "- ## actions to perform"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "'''\n",
    " teacher_prefix                                                                   one-hot-encoding\n",
    " school_state                                                                     one-hot-encoding\n",
    " submission_y                                                                                 none   \n",
    " project_grade_category                                                           one-hot-encoding\n",
    " project_subject_categories                                                       one-hot-encoding\n",
    " project_subject_subcategories                                                    one-hot-encoding\n",
    " project_title                                                                           bow-tfidf\n",
    " title_len                                                                                    none\n",
    " teacher_number_of_previously_posted_projects                                                 none\n",
    " essay                                                                                   bow-tfidf\n",
    " essay_len                                                                                    none\n",
    " nrm_price                                                                                    none\n",
    " std_price                                                                                    none\n",
    " quantity                                                                                     none\n",
    " project_is_approved                                                                  decision-var   '''     "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "- ## Spliting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_trainx,d_testx,d_trainy,d_testy = train_test_split(per_data.iloc[:,:-1],per_data.iloc[:,-1],stratify=per_data.iloc[:,-1],test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_trainx.shape,d_trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_trainy.value_counts(normalize=True),d_testy.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trainx,d_cvx,ds_trainy,d_cvy = train_test_split(d_trainx,d_trainy,stratify=d_trainy,test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trainy.value_counts(normalize=True),d_cvy.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trainy.value_counts(),d_cvy.value_counts()"
   ]
  },
  {
   "source": [
    "- # 1) Vectorization\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- ## 1.1) BOW"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_essay = CountVectorizer(min_df=10)\n",
    "ds_trainx_essay = vec_essay.fit_transform(ds_trainx['essay'])\n",
    "d_cvx_essay=vec_essay.transform(d_cvx['essay'])\n",
    "d_testx_essay = vec_essay.transform(d_testx['essay'])\n",
    "ds_trainx_essay.toarray().shape,d_cvx_essay.toarray().shape,d_testx_essay.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_title = CountVectorizer(min_df=10)\n",
    "ds_trainx_title = vec_title.fit_transform(ds_trainx['project_title'])\n",
    "d_cvx_title=vec_title.transform(d_cvx['project_title'])\n",
    "d_testx_title = vec_title.transform(d_testx['project_title'])\n",
    "ds_trainx_title.toarray().shape,d_cvx_title.toarray().shape,d_testx_title.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_essay2 = CountVectorizer(min_df=10)\n",
    "d_trainx_essay = vec_essay2.fit_transform(d_trainx['essay'])\n",
    "d_testx_essay2 = vec_essay2.transform(d_testx['essay'])\n",
    "d_trainx_essay.toarray().shape,d_testx_essay2.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_title2 = CountVectorizer(min_df=10)\n",
    "d_trainx_title = vec_title2.fit_transform(d_trainx['project_title'])\n",
    "d_testx_title2 = vec_title2.transform(d_testx['project_title'])\n",
    "d_trainx_title.toarray().shape,d_testx_title2.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct_trn_data = per_data.drop(['essay','project_title'],axis=1)\n",
    "# d_trainx.drop(['essay','project_title'],axis=1,inplace=True)cal\n",
    "# ds_trainx.drop(['essay','project_title'],axis=1,inplace=True)\n",
    "# d_testx.drop(['essay','project_title'],axis=1,inplace=True)\n",
    "# d_cvx.drop(['essay','project_title'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text_features = ['project_subject_subcategories','project_subject_categories','school_state','project_grade_category','teacher_prefix']\n",
    "# text_transformer = Pipeline(steps=[\n",
    "#     ('vect', CountVectorizer(binary=True))\n",
    "# ])\n",
    "\n",
    "# for x in text_features:\n",
    "#     ct = ColumnTransformer(transformers=[('text', CountVectorizer(binary=True), x)])\n",
    "#     ds_trainx_vec = preprocessor.fit_transform(ds_trainx)\n",
    "#     print(ds_trainx_vec.toarray().shape)\n",
    "\n",
    "# clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "# clf.fit(ds_trainx)\n",
    "\n",
    "vec_ct = ColumnTransformer(transformers=[('short',OneHotEncoder(),['project_subject_subcategories','project_subject_categories','school_state','project_grade_category','teacher_prefix'])],remainder='passthrough')\n",
    "vec_ct.fit(per_data.drop(['essay','project_title'],axis=1).iloc[:,:-1])\n",
    "ds_trainx_vec = vec_ct.transform(ds_trainx.drop(['essay','project_title'],axis=1))\n",
    "d_testx_vec = vec_ct.transform(d_testx.drop(['essay','project_title'],axis=1))\n",
    "d_cvx_vec = vec_ct.transform(d_cvx.drop(['essay','project_title'],axis=1))\n",
    "d_trainx_vec = vec_ct.transform(d_trainx.drop(['essay','project_title'],axis=1))\n",
    "# d_testx_vec2 = vec_ct.transform(d_testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trainx_vec.toarray().shape,d_testx_vec.toarray().shape,d_cvx_vec.toarray().shape,d_trainx_vec.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trainx_csr = hstack((ds_trainx_essay,ds_trainx_title,ds_trainx_vec)).tocsr()\n",
    "d_testx_csr = hstack((d_testx_essay,d_testx_title,d_testx_vec)).tocsr()\n",
    "d_cvx_csr = hstack((d_cvx_essay,d_cvx_title,d_cvx_vec)).tocsr()\n",
    "d_trainx_csr = hstack((d_trainx_essay,d_trainx_title,d_trainx_vec)).tocsr()\n",
    "d_testx2_csr = hstack((d_testx_essay2,d_testx_title2,d_testx_vec)).tocsr()\n",
    "ds_trainx_csr.shape,d_testx_csr.shape,d_cvx_csr.shape,d_trainx_csr.shape,d_testx2_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datafiles/doners/donerschoose_pickle.pickle','wb') as pik:\n",
    "    pickle.dump(ds_trainx_csr,pik)\n",
    "    pickle.dump(d_testx_csr,pik)\n",
    "    pickle.dump(d_cvx_csr,pik)\n",
    "    pickle.dump(d_trainx_csr,pik)\n",
    "    pickle.dump(d_testx2_csr,pik)\n",
    "    pik.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datafiles/doners/donerschoose_pickle.pickle','rb') as pik:\n",
    "    ds_trainx_csr = pickle.load(pik)\n",
    "    d_testx_csr = pickle.load(pik)\n",
    "    d_cvx_csr = pickle.load(pik)\n",
    "    d_trainx_csr = pickle.load(pik)\n",
    "    d_testx2_csr = pickle.load(pik)\n",
    "    pik.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datafiles/doners/donerschoose_pickle_y.pickle','wb') as pik:\n",
    "    pickle.dump(ds_trainy,pik)\n",
    "    pickle.dump(d_testy,pik)\n",
    "    pickle.dump(d_cvy,pik)\n",
    "    pickle.dump(d_trainy,pik)\n",
    "    pickle.dump(d_testy,pik)\n",
    "    pik.close()"
   ]
  },
  {
   "source": [
    "- # Naive Bais"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_roc(clf,X,Y,x,y,*cv):\n",
    "    y_probability = clf.predict_proba(X)[:,1]\n",
    "    fpr, tpr, threshold = roc_curve(Y, y_probability)\n",
    "    roc_auc = roc_auc_score(Y, y_probability)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'g', label = 'AUC-Test = %0.2f' % roc_auc)\n",
    "\n",
    "    y_probability = clf.predict_proba(x)[:,1]\n",
    "    fpr, tpr, threshold = roc_curve(y, y_probability)\n",
    "    roc_auc = roc_auc_score(y, y_probability)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC-Train = %0.2f' % roc_auc)\n",
    "\n",
    "    if(len(cv)==2):\n",
    "        y_probability = clf.predict_proba(cv[0])[:,1]\n",
    "        fpr, tpr, threshold = roc_curve(cv[1], y_probability)\n",
    "        roc_auc = roc_auc_score(cv[1], y_probability)\n",
    "        plt.plot(fpr, tpr, 'y', label = 'AUC-CV = %0.2f' % roc_auc)\n",
    "\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "def Confusion_mat(clf,X,Y,x,y,*cv):\n",
    "    plot_confusion_matrix(clf,X,Y)\n",
    "    plt.title('Confusion Matrix on Test Data')\n",
    "    plot_confusion_matrix(clf,x,y)\n",
    "    plt.title('Confusion Matrix on Train Data')\n",
    "    if(len(cv)==2):\n",
    "        plot_confusion_matrix(clf,cv[0],cv[1])\n",
    "        plt.title('Confusion Matrix on CV Data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = list([10**-5,10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**5,10**6])\n",
    "auroc=list()\n",
    "for aph in alpha:\n",
    "    clf = MultinomialNB(alpha=aph)\n",
    "    clf.fit(ds_trainx_csr,ds_trainy)\n",
    "    auroc.append(roc_auc_score(d_cvy,clf.predict_proba(d_cvx_csr)[:,1]))\n",
    "clf = MultinomialNB(alpha=alpha[auroc.index(max(auroc))])\n",
    "clf.fit(ds_trainx_csr,ds_trainy)\n",
    "print('Best alpha:',clf.alpha)\n",
    "Plot_roc(clf,d_testx_csr,d_testy,ds_trainx_csr,ds_trainy,d_cvx_csr,d_cvy)\n",
    "Confusion_mat(clf,d_testx_csr,d_testy,ds_trainx_csr,ds_trainy,d_cvx_csr,d_cvy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(MultinomialNB(),{'alpha':alpha},scoring='roc_auc',cv=2,verbose=2,n_jobs=-1,return_train_score=True)\n",
    "gs_clf.fit(d_trainx_csr,d_trainy)\n",
    "print(gs_clf.best_estimator_)\n",
    "print('='*150)\n",
    "Plot_roc(gs_clf,d_testx2_csr,d_testy,d_trainx_csr,d_trainy)\n",
    "Confusion_mat(gs_clf,d_testx2_csr,d_testy,d_trainx_csr,d_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set1  = vec_essay.get_feature_names()+vec_title.get_feature_names()+vec_ct.get_feature_names()\n",
    "feat_set2  = vec_essay2.get_feature_names()+vec_title2.get_feature_names()+vec_ct.get_feature_names()\n",
    "indices = clf.feature_log_prob_[1].argsort()[-20:][::-1]\n",
    "indices2 = clf.feature_log_prob_[0].argsort()[-20:][::-1]\n",
    "indices3 = gs_clf.best_estimator_.feature_log_prob_[1].argsort()[-20:][::-1]\n",
    "indices4 = gs_clf.best_estimator_.feature_log_prob_[0].argsort()[-20:][::-1]\n",
    "pd.DataFrame({'(CV) positive':np.array(feat_set1)[indices],'(K-CV) positive':np.array(feat_set2)[indices3],'(CV) negative':np.array(feat_set1)[indices2],'(K-CV) negative':np.array(feat_set2)[indices4]})"
   ]
  },
  {
   "source": [
    "# TFIDF Naive-Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_essay = TfidfVectorizer(min_df=10)\n",
    "ds_trainx_essay = vec_essay.fit_transform(ds_trainx['essay'])\n",
    "d_cvx_essay=vec_essay.transform(d_cvx['essay'])\n",
    "d_testx_essay = vec_essay.transform(d_testx['essay'])\n",
    "# ds_trainx_essay.toarray().shape,d_cvx_essay.toarray().shape,d_testx_essay.toarray().shape\n",
    "\n",
    "vec_title = TfidfVectorizer(min_df=10)\n",
    "ds_trainx_title = vec_title.fit_transform(ds_trainx['project_title'])\n",
    "d_cvx_title=vec_title.transform(d_cvx['project_title'])\n",
    "d_testx_title = vec_title.transform(d_testx['project_title'])\n",
    "# ds_trainx_title.toarray().shape,d_cvx_title.toarray().shape,d_testx_title.toarray().shape\n",
    "\n",
    "vec_essay2 = TfidfVectorizer(min_df=10)\n",
    "d_trainx_essay = vec_essay2.fit_transform(d_trainx['essay'])\n",
    "d_testx_essay2 = vec_essay2.transform(d_testx['essay'])\n",
    "# d_trainx_essay.toarray().shape,d_testx_essay2.toarray().shape\n",
    "\n",
    "vec_title2 = TfidfVectorizer(min_df=10)\n",
    "d_trainx_title = vec_title2.fit_transform(d_trainx['project_title'])\n",
    "d_testx_title2 = vec_title2.transform(d_testx['project_title'])\n",
    "d_trainx_title.toarray().shape,d_testx_title2.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trainx_csr = hstack((ds_trainx_essay,ds_trainx_title,ds_trainx_vec)).tocsr()\n",
    "d_testx_csr = hstack((d_testx_essay,d_testx_title,d_testx_vec)).tocsr()\n",
    "d_cvx_csr = hstack((d_cvx_essay,d_cvx_title,d_cvx_vec)).tocsr()\n",
    "d_trainx_csr = hstack((d_trainx_essay,d_trainx_title,d_trainx_vec)).tocsr()\n",
    "d_testx2_csr = hstack((d_testx_essay2,d_testx_title2,d_testx_vec)).tocsr()\n",
    "ds_trainx_csr.shape,d_testx_csr.shape,d_cvx_csr.shape,d_trainx_csr.shape,d_testx2_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../datafiles/doners/donerschoose_pickle_tdifd.pickle','wb') as pik:\n",
    "    pickle.dump(ds_trainx_csr,pik)\n",
    "    pickle.dump(d_testx_csr,pik)\n",
    "    pickle.dump(d_cvx_csr,pik)\n",
    "    pickle.dump(d_trainx_csr,pik)\n",
    "    pickle.dump(d_testx2_csr,pik)\n",
    "    pik.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datafiles/doners/donerschoose_pickle_tdifd.pickle','rb') as pik:\n",
    "    ds_trainx_csr = pickle.load(pik)\n",
    "    d_testx_csr = pickle.load(pik)\n",
    "    d_cvx_csr = pickle.load(pik)\n",
    "    d_trainx_csr = pickle.load(pik)\n",
    "    d_testx2_csr = pickle.load(pik)\n",
    "    pik.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = list([10**-5,10**-4,10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3,10**5,10**6])\n",
    "auroc=list()\n",
    "for aph in alpha:\n",
    "    clf = MultinomialNB(alpha=aph)\n",
    "    clf.fit(ds_trainx_csr,ds_trainy)\n",
    "    auroc.append(roc_auc_score(d_cvy,clf.predict_proba(d_cvx_csr)[:,1]))\n",
    "clf = MultinomialNB(alpha=alpha[auroc.index(max(auroc))])\n",
    "clf.fit(ds_trainx_csr,ds_trainy)\n",
    "print('Best alpha:',clf.alpha)\n",
    "Plot_roc(clf,d_testx_csr,d_testy,ds_trainx_csr,ds_trainy,d_cvx_csr,d_cvy)\n",
    "Confusion_mat(clf,d_testx_csr,d_testy,ds_trainx_csr,ds_trainy,d_cvx_csr,d_cvy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(MultinomialNB(),{'alpha':alpha},scoring='roc_auc',cv=2,verbose=2,n_jobs=-1,return_train_score=True)\n",
    "gs_clf.fit(d_trainx_csr,d_trainy)\n",
    "print(gs_clf.best_estimator_)\n",
    "print('='*150)\n",
    "Plot_roc(gs_clf,d_testx2_csr,d_testy,d_trainx_csr,d_trainy)\n",
    "Confusion_mat(gs_clf,d_testx2_csr,d_testy,d_trainx_csr,d_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set1  = vec_essay.get_feature_names()+vec_title.get_feature_names()+vec_ct.get_feature_names()\n",
    "feat_set2  = vec_essay2.get_feature_names()+vec_title2.get_feature_names()+vec_ct.get_feature_names()\n",
    "indices = clf.feature_log_prob_[1].argsort()[-20:][::-1]\n",
    "indices2 = clf.feature_log_prob_[0].argsort()[-20:][::-1]\n",
    "indices3 = gs_clf.best_estimator_.feature_log_prob_[1].argsort()[-20:][::-1]\n",
    "indices4 = gs_clf.best_estimator_.feature_log_prob_[0].argsort()[-20:][::-1]\n",
    "pd.DataFrame({'(CV) positive':np.array(feat_set1)[indices],'(K-CV) positive':np.array(feat_set2)[indices3],'(CV) negative':np.array(feat_set1)[indices2],'(K-CV) negative':np.array(feat_set2)[indices4]})"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ['project_subject_subcategories','project_subject_categories','school_state','project_grade_category','teacher_prefix']\n",
    " = pd.DataFrame()\n",
    "res_d_test = pd.DataFrame()\n",
    "d_train = pd.concat([d_trainx,d_trainy],axis=1,ignore_index=False)\n",
    "d_test = pd.concat([d_testx,d_testy],axis=1,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_coding(x,nm):\n",
    "    res_d_train[nm+'_1'] = d_train.groupby(x)['project_is_approved'].transform(lambda x: sum(x)/len(x))\n",
    "    res_d_train[nm+'_0'] = 1-res_d_train[nm+'_1']\n",
    "    map_dict = d_train.groupby(x)['project_is_approved'].apply(mean).to_dict()\n",
    "    res_d_test[nm+'_1'] = d_test[x].map(map_dict).fillna(0.5)\n",
    "    res_d_test[nm+'_0'] = 1-res_d_test[nm+'_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_coding('project_subject_subcategories','pss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d_test,res_d_test.sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d_train,res_d_train.sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_coding('project_subject_subcategories','pss')  # Already done\n",
    "response_coding('teacher_prefix','tp')\n",
    "response_coding('project_grade_category','pgc')\n",
    "response_coding('school_state','ss')\n",
    "response_coding('project_subject_categories','psc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d_train.head() , res_d_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_d_test.head(), res_d_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_trainx_csr = hstack((ds_trainx_essay,ds_trainx_title,ds_trainx_vec)).tocsr()\n",
    "# d_testx_csr = hstack((d_testx_essay,d_testx_title,d_testx_vec)).tocsr()\n",
    "# d_cvx_csr = hstack((d_cvx_essay,d_cvx_title,d_cvx_vec)).tocsr()\n",
    "d_trainx_csr = hstack((d_trainx_essay,d_trainx_title,res_d_train)).tocsr()\n",
    "d_testx2_csr = hstack((d_testx_essay2,d_testx_title2,res_d_test)).tocsr()\n",
    "# ds_trainx_csr.shape,d_testx_csr.shape,d_cvx_csr.shape,\n",
    "d_trainx_csr.shape,d_testx2_csr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datafiles/doners/donerschoose_pickle_tdifd_res.pickle','wb') as pik:\n",
    "    # pickle.dump(ds_trainx_csr,pik)\n",
    "    # pickle.dump(d_testx_csr,pik)\n",
    "    # pickle.dump(d_cvx_csr,pik)\n",
    "    pickle.dump(d_trainx_csr,pik)\n",
    "    pickle.dump(d_testx2_csr,pik)\n",
    "    pik.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}