{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitplaygroundconda181cc4e8a1f74f20aba28f8bf4ca7131",
   "display_name": "Python 3.8.2 64-bit ('playground': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(364171, 500) [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 2 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n----------------------------------------------------------------------------------------------------------------------------------------------\n(364171, 500) [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 3 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n----------------------------------------------------------------------------------------------------------------------------------------------\n(364171, 500) [0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.1250091  0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.17836132 0.20792648 0.16430364 0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.11828941\n 0.         0.         0.         0.         0.         0.\n 0.31721005 0.2124529  0.         0.         0.         0.\n 0.         0.         0.17124054 0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.19877621 0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.16345348 0.         0.         0.         0.         0.\n 0.16822947 0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.1133605  0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.1904391  0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.07281537 0.         0.         0.         0.\n 0.         0.         0.         0.06876212 0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.10850045 0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.13273982 0.         0.18102552 0.\n 0.08557522 0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.1494937  0.         0.12940076 0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.24730535 0.19801447 0.         0.         0.         0.\n 0.1924234  0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.21433693 0.19487476 0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.27527597 0.         0.         0.         0.\n 0.         0.         0.11607449 0.         0.         0.\n 0.         0.         0.         0.         0.20641258 0.\n 0.         0.         0.12372791 0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.07029306 0.         0.\n 0.1587362  0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.06724431 0.16691963\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.        ]\n----------------------------------------------------------------------------------------------------------------------------------------------\n(364171, 50) [ 0.03843716 -0.13654825  0.27757554 -0.62577171  0.04878765 -0.47531997\n -0.23224694  0.95713528 -0.15943907 -0.14989209 -0.4952686  -0.26271641\n -0.79561397 -0.55096844 -1.26832113  0.08285021 -0.28235228 -0.0694987\n -0.58058887 -0.56461811  0.23618219  0.33347143  0.10550685  0.00397338\n -0.73947738  0.41673188  0.07825652  0.82032323  1.16018902  0.73292807\n  0.54749254 -0.1070863  -0.31513472 -1.01863425  0.02664523 -0.41122598\n -0.32641836  0.05964659 -0.2820572   0.95531951 -0.54041798 -1.28046966\n -0.66122796  1.4723898   0.2999091  -1.4607144  -0.0426597  -0.19204686\n -0.020366    0.3818206 ]\n----------------------------------------------------------------------------------------------------------------------------------------------\n(1000, 50) [-0.0509839  -0.16574168  0.30716829 -0.44826465 -0.36388874 -0.53695004\n -0.15272259  0.67296482 -0.0128032  -0.20437092 -0.62755522 -0.33309588\n -0.57458339 -0.48092003 -1.31869507 -0.04124138 -0.47830399 -0.11563859\n -0.799503   -0.2864111   0.32388327  0.40108873 -0.01473334  0.63636606\n -0.71677481  0.72531534  0.71640292  1.06612554  1.15809431  0.59766963\n  0.2470274   0.06871765 -0.57651254 -0.98319873 -0.27029041 -0.44798588\n -0.15379701  0.48439077 -0.61636203  1.12312677 -0.94104636 -1.08965573\n -0.64335752  0.94730646  0.31289621 -1.52895595  0.23859477 -0.28508478\n -0.11512199  0.09190397]\n"
    }
   ],
   "source": [
    "with open('../datafiles/pickles/affr_bow_500','rb') as affr_bow_500:\n",
    "    affr_bow_500 = pickle.load(affr_bow_500).toarray()\n",
    "    print(affr_bow_500.shape,affr_bow_500[0])\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "with open('../datafiles/pickles/affr_bigram_bow_500','rb') as affr_bigram_bow_500:\n",
    "    affr_bigram_bow_500 = pickle.load(affr_bigram_bow_500).toarray()\n",
    "    print(affr_bigram_bow_500.shape,affr_bigram_bow_500[0])\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "with open('../datafiles/pickles/affr_ngram_tfidf_500','rb') as affr_ngram_tfidf_500:\n",
    "    affr_ngram_tfidf_500 = pickle.load(affr_ngram_tfidf_500).toarray()\n",
    "    print(affr_ngram_tfidf_500.shape,affr_ngram_tfidf_500[0])\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "with open('../datafiles/pickles/avg_w2v','rb') as avg_w2v:\n",
    "    avg_w2v = np.array(pickle.load(avg_w2v))\n",
    "    print(avg_w2v.shape,avg_w2v[0])\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "with open('../datafiles/pickles/tdifd_weighted_w2v','rb') as tdifd_weighted_w2v:\n",
    "    tdifd_weighted_w2v = np.array(pickle.load(tdifd_weighted_w2v))\n",
    "    print(tdifd_weighted_w2v.shape,tdifd_weighted_w2v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../datafiles/amazon_reviews.sqlite')\n",
    "data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score!=3\"\"\",conn)\n",
    "def scr(s):\n",
    "    if(s>3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Score'] = data['Score'].apply(scr)\n",
    "cus_data = data.drop_duplicates(subset={'UserId','ProfileName', 'Time', 'Text'},keep='first')\n",
    "cus_data = cus_data[cus_data['HelpfulnessNumerator']<=cus_data['HelpfulnessDenominator']]\n",
    "Scr = cus_data.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Knn:\n",
    "    def __init__(self,X,Y,time_splits=10,algorithm='auto'):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.time_splits = time_splits\n",
    "        self.algorithm = algorithm\n",
    "        \n",
    "    def KNN_TS(self):\n",
    "        X_train_n_cv, X_test, Y_train_n_cv, Y_test = train_test_split(self.X,self.Y,test_size=0.3)\n",
    "        tscv = TimeSeriesSplit()\n",
    "        TimeSeriesSplit(max_train_size=None, n_splits=self.time_splits)\n",
    "        scrs = list()\n",
    "        for n in tqdm(range(1,30)):\n",
    "            cv_score = list()\n",
    "            train_score = list()\n",
    "            for train_index, cv_index in tscv.split(X_train_n_cv):\n",
    "                X_train,Y_train = X_train_n_cv[train_index],Y_train_n_cv[train_index]\n",
    "                X_cv,Y_cv = X_train_n_cv[cv_index],Y_train_n_cv[cv_index]\n",
    "                model = KNeighborsClassifier(n_neighbors = n, algorithm = self.algorithm)  \n",
    "                model.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}