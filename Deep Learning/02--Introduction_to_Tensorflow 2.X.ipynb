{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-2.0 in Action "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TensorFlow is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices.\n",
    "> Originally developed by researchers and engineers from the Google Brain team within Googleâ€™s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">TensorFlow is tested and supported on the following 64-bit systems:\n",
    "\n",
    ">1.Ubuntu 16.04 or later\n",
    "\n",
    ">2.Windows 7 or later\n",
    "\n",
    ">3.macOS 10.12.6 (Sierra) or later (no GPU support)\n",
    "\n",
    ">4.Raspbian 9.0 or later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **pip install tensorflow==2.0.0**\n",
    "\n",
    "> To run from Anaconda Prompt\n",
    "\n",
    "> **!pip install tensorflow==2.0.0**\n",
    "\n",
    "> To run from Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Both Tensorflow 2.0 and Keras have been released for four years (Keras was released in March 2015, and Tensorflow was released in November of the same year). The rapid development of deep learning in the past days, we also know some problems of Tensorflow1.x and Keras:`\n",
    "\n",
    "* Using Tensorflow means programming static graphs, which is difficult and inconvenient for programs that are familiar with imperative programming\n",
    "\n",
    "* Tensorflow api is powerful and flexible, but it is more complex, confusing and difficult to use.\n",
    "\n",
    "* Keras api is productive and easy to use, but lacks flexibility for research\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorFlow version: 2.4.1\nKeras version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tensorflow2.0 is a combination design of Tensorflow1.x and Keras. Considering user feedback and framework development over the past four years, it largely solves the above problems and will become the future machine learning platform.`\n",
    "\n",
    "> Tensorflow 2.0 is built on the following core ideas:\n",
    "\n",
    "\n",
    "* The coding is more pythonic, so that users can get the results immediately like they are programming in numpy\n",
    "* Retaining the characteristics of static graphs (for performance, distributed, and production deployment), this makes TensorFlow fast, scalable, and ready for production.\n",
    "* Using Keras as a high-level API for deep learning, making Tensorflow easy to use and efficient\n",
    "* Make the entire framework both high-level features (easy to use, efficient, and not flexible) and low-level features (powerful and scalable, not easy to use, but very flexible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Eager execution is by default in TensorFlow 2.0 and, it needs no special setup.\n",
    ">The following below code can be used to find out whether a CPU or GPU is in use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU/CPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    }
   ],
   "source": [
    "variable = tf.Variable([3, 3])\n",
    "if tf.test.is_gpu_available():\n",
    "    print('GPU')\n",
    "    print('GPU #0?')\n",
    "    print(var.device.endswith('GPU:0'))\n",
    "else:\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron = tf.constant(42)\n",
    "ineuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fd4b34fa6f63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mineuron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "ineuron.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_1:0' shape=() dtype=int64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron1 = tf.constant(1, dtype = tf.int64)\n",
    "ineuron1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ineuron_x = tf.constant([[4,2],[9,5]])\n",
    "print(ineuron_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f202df546c8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mineuron_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "ineuron_x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print('shape:',ineuron_x.shape)\n",
    "print(ineuron_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commonly used method is to generate constant tf.ones and the tf.zeros like of numpy np.ones & np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ones:0\", shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.ones(shape=(2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros:0\", shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.zeros(shape=(3,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "const2 = tf.constant([[3,4,5], [3,4,5]]);tf\n",
    "const1 = tf.constant([[1,2,3], [1,2,3]]);\n",
    "result = tf.add(const1, const2);\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We have defined two constants and we add one value to the other. \n",
    ">As a result, we got a Tensor object with the result of the adding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_normal:0' shape=(2, 2) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(2,2),mean=0,stddev=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_uniform:0' shape=(2, 2) dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape=(2,2),minval=0,maxval=10,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">A variable is a special tensor that is used to store variable values â€‹â€‹and needs to be initialized with some values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,\n",
       " <tf.Variable 'Variable_1:0' shape=() dtype=int32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(2, 2, 3) dtype=float32_ref>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var0 = 24 # python variable\n",
    "var1 = tf.Variable(42) # rank 0 tensor\n",
    "var2 = tf.Variable([ [ [0., 1., 2.], [3., 4., 5.] ], [ [6., 7., 8.], [9., 10., 11.] ] ]) #rank 3 tensor\n",
    "var0, var1, var2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">TensorFlow will infer the datatype, defaulting to tf.float32 for floats and tf.int32 for integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The datatype can be explicitly specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64_ref"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_var64 = tf.Variable(89, dtype = tf.float64)\n",
    "float_var64.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TensorFlow has a large number of built-in datatypes.`\n",
    "* tf.float16: 16-bit half-precision floating-point.\n",
    "* tf.float32: 32-bit single-precision floating-point.\n",
    "* tf.float64: 64-bit double-precision floating-point.\n",
    "* tf.bfloat16: 16-bit truncated floating-point.\n",
    "* tf.complex64: 64-bit single-precision complex.\n",
    "* tf.complex128: 128-bit double-precision complex.\n",
    "* tf.int8: 8-bit signed integer.\n",
    "* tf.uint8: 8-bit unsigned integer.\n",
    "* tf.uint16: 16-bit unsigned integer.\n",
    "* tf.uint32: 32-bit unsigned integer.\n",
    "* tf.uint64: 64-bit unsigned integer.\n",
    "* tf.int16: 16-bit signed integer.\n",
    "* tf.int32: 32-bit signed integer.\n",
    "* tf.int64: 64-bit signed integer.\n",
    "* tf.bool: Boolean.\n",
    "* tf.string: String.\n",
    "* tf.qint8: Quantized 8-bit signed integer.\n",
    "* tf.quint8: Quantized 8-bit unsigned integer.\n",
    "* tf.qint16: Quantized 16-bit signed integer.\n",
    "* tf.quint16: Quantized 16-bit unsigned integer.\n",
    "* tf.qint32: Quantized 32-bit signed integer.\n",
    "* tf.resource: Handle to a mutable resource.\n",
    "* tf.variant: Values of arbitrary types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To reassign a variable, use var.assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_4:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_reassign = tf.Variable(89.)\n",
    "var_reassign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_4:0' shape=() dtype=float32_ref>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_reassign.assign(98.)\n",
    "var_reassign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_5:0' shape=(2, 2) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "initial_value = tf.random.normal(shape=(2,2))\n",
    "a = tf.Variable(initial_value)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We can assign \"=\" with assign (value), or assign_add (value) with \"+ =\", or assign_sub (value) with \"-=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6fafb0856610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_value = tf.random.normal(shape=(2, 2))\n",
    "# a.assign(new_value)\n",
    "# print(a.numpy())\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        assert a[i, j] == new_value[i, j] # This thing dosen't work. I don't know why Ineuron has put this in their training notebook.\n",
    "new_value,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-7e63bc5c3727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0madded_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "added_value = tf.random.normal(shape=(2,2))\n",
    "a.assign_add(added_value)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        assert a[i,j] == new_value[i,j]+added_value[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shaping a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [10., 11., 12.], [13., 14., 15.] ], [ [16., 17., 18.], [19., 20., 21.] ] ]) # tensor variable\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors can be reshaped and retain the same values which is required for constructing Neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[10., 11., 12., 13., 14., 15.],\n",
       "       [16., 17., 18., 19., 20., 21.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "tensor1 = tf.reshape(tensor,[2,6]) # 2 rows 6 cols\n",
    "#tensor2 = tf.reshape(tensor,[1,12]) # 1 rows 12 cols\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=float32, numpy=\n",
       "array([[10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21.]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tensor2 = tf.reshape(tensor,[1,12]) # 1 row 12 columns\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The rank of a tensor is defined as the number of dimensions, which is the number of indices that are required to specify any particular element of that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=202, shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">(the shape is () because the output here is a scalar value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying an element of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=18.0>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tensor3 = tensor[1, 0, 2] # slice 1, row 0, column 2\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Casting a tensor to a NumPy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[10. 11. 12.]\n",
      "  [13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18.]\n",
      "  [19. 20. 21.]]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "print(tensor[1, 0, 2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the size or length of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_size = tf.size(input=tensor).numpy()\n",
    "tensor_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the datatype of a tensor\n",
    "tensor3.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow mathematical operations\n",
    ">Can be used as numpy for artificial operations. Tensorflow can not execute these operations on the GPU or TPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.56271744 -0.55164266]\n",
      " [ 0.27730447  0.43937662]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.46430582  2.074887  ]\n",
      " [ 0.6814727  -0.03568114]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.09841162  1.5232444 ]\n",
      " [ 0.9587772   0.40369546]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.00968485 2.3202734 ]\n",
      " [0.9192537  0.16297002]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.90627575 4.5870833 ]\n",
      " [2.608505   1.497348  ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "c = a + b\n",
    "d = tf.square(c)\n",
    "e = tf.exp(c)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=128>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "aa,ab = tf.Variable(2),tf.Variable(7)\n",
    "aa**ab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing element-wise primitive tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=233, shape=(2, 2, 3), dtype=float32, numpy=\n",
       "array([[[100., 121., 144.],\n",
       "        [169., 196., 225.]],\n",
       "\n",
       "       [[256., 289., 324.],\n",
       "        [361., 400., 441.]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in Tensorflow\n",
    "\n",
    ">Element-wise tensor operations support broadcasting in the same way that NumPy arrays do.\n",
    "\n",
    ">The simplest example is multiplication of  a tensor by a scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[40. 44. 48.]\n",
      "  [52. 56. 60.]]\n",
      "\n",
      " [[64. 68. 72.]\n",
      "  [76. 80. 84.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor4 = tensor*4\n",
    "print(tensor4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=241, shape=(1, 1), dtype=int32, numpy=array([[64]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_u = tf.constant([[6,7,6]])\n",
    "matrix_v = tf.constant([[3,4,3]])\n",
    "tf.matmul(matrix_u, tf.transpose(a=matrix_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting a tensor to another datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=242, shape=(2, 6), dtype=int32, numpy=\n",
       "array([[10, 11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20, 21]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.cast(tensor1, dtype=tf.int32)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Expected tensor with type tf.int32 not tf.float32",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2cffdc5bce8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 265\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m       raise TypeError(\"Expected tensor with type %r not %r\" % (\n\u001b[1;32m---> 90\u001b[1;33m           dtype, value.dtype))\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected tensor with type tf.int32 not tf.float32"
     ]
    }
   ],
   "source": [
    "t = tf.constant(tensor1,dtype=tf.int32)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[10, 11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20, 21]])>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "t = tf.constant(tensor1.numpy(),dtype=tf.int32)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Casting with truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=244, shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = tf.cast(tf.constant(4.9), dtype=tf.int32)\n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ragged tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A ragged tensor is a tensor having one or more ragged dimensions. Ragged dimensions are dimensions that have slices having various lengths.There are a variety of methods for the declaration of ragged arrays, the simplest way is declaring a constant ragged array.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below example shows how to declare a constant ragged array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[9, 7, 4, 3], [], [11, 12, 8], [3], [7, 8]]>\n",
      "tf.Tensor([9 7 4 3], shape=(4,), dtype=int32)\n",
      "tf.Tensor([], shape=(0,), dtype=int32)\n",
      "tf.Tensor([11 12  8], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3], shape=(1,), dtype=int32)\n",
      "tf.Tensor([7 8], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ragged =tf.ragged.constant([[9, 7, 4, 3], [], [11, 12, 8], [3], [7,8]])\n",
    "print(ragged)\n",
    "print(ragged[0,:])\n",
    "print(ragged[1,:])\n",
    "print(ragged[2,:])\n",
    "print(ragged[3,:])\n",
    "print(ragged[4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squared difference of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=int32, numpy=array([  0, 100,   0,   0,  25])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([16,  9,  4, 49, 36])>)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "varx = [4,5,6,1,2]\n",
    "varxx = [4,15,6,1,-3]\n",
    "vary = 8\n",
    "varz = tf.math.squared_difference(varx,varxx)\n",
    "varzz = tf.math.squared_difference(varx,vary) \n",
    "varz,varzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Function available\n",
    ">tf.reduce_mean()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Similar to np.mean, except that it infers the return datatype from the input tensor, whereas np.mean allows you to specify the output type`\n",
    "\n",
    "`tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a constant\n",
    "numbers = tf.constant([[8., 9.], [1., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean across all axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=377, shape=(), dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers) #default axis = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean across columns (reduce rows) with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=379, shape=(2,), dtype=float32, numpy=array([4.5, 5.5], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When keepdims = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=381, shape=(1, 2), dtype=float32, numpy=array([[4.5, 5.5]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers, axis=0, keepdims=True) #the reduced axis is retained with a length of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mean across rows (reduce columns) with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=383, shape=(2,), dtype=float32, numpy=array([8.5, 1.5], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When keepdims= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=385, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[8.5],\n",
       "       [1.5]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers, axis=1, keepdims=True) #the reduced axis is retained with a length of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Random values generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tf.random.normal()\n",
    "\n",
    ">tf.random.normal() outputs a tensor of the given shape filled with values of the dtype type from a normal distribution.\n",
    "\n",
    ">The function is as follows:\n",
    "    \n",
    "`tf.random.normal(shape, mean = 0, stddev =2, dtype=tf.float32, seed=None, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[13.419874  9.652067]\n",
      " [ 8.206388 10.20897 ]\n",
      " [ 9.400301  9.270695]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.normal(shape = (3,2), mean=10, stddev=2, dtype=tf.float32, seed=None, name=None)\n",
    "randon_num = tf.random.normal(shape = (3,2), mean=10.0, stddev=2.0)\n",
    "print(randon_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  tf.random.uniform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The function is this:\n",
    "    \n",
    ">tf.random.uniform(shape, minval = 0, maxval= None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`This outputs a tensor of the given shape filled with values from a uniform distribution in the range minval to maxval, where the lower bound is inclusive but the upper bound isn't.\n",
    "\n",
    "Example:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=404, shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.4859345 , 0.667521  , 0.28568578, 0.86824465],\n",
       "       [0.28643095, 0.81876636, 0.6277267 , 0.8998866 ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape = (2,4), minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 6]\n",
      " [5 2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 7]\n",
      " [9 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(11)\n",
    "random_num1 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "random_num2 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "print(random_num1) #Call 1\n",
    "print(random_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 6]\n",
      " [5 2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 7]\n",
      " [9 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(11) #same seed\n",
    "random_num1 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "random_num2 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "print(random_num1) #Call 2\n",
    "print(random_num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practical example of Random values using Dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5  5 10]\n",
      " [ 4  3  7]\n",
      " [ 5  3  8]\n",
      " [ 3  3  6]\n",
      " [ 1  4  5]\n",
      " [ 4  1  5]\n",
      " [ 5  1  6]\n",
      " [ 6  4 10]\n",
      " [ 3  3  6]\n",
      " [ 2  3  5]], shape=(10, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dice11 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))\n",
    "dice12 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))\n",
    "\n",
    "# lets ADD\n",
    "dice_sum1 = dice11 + dice12\n",
    "# We've got three separate 10x1 matrices. To produce a single 10x3 matrix, we'll concatenate them along dimension 1.\n",
    "finale_matrix = tf.concat(values=[dice11, dice12, dice_sum1], axis=1)\n",
    "print(finale_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the indices of the largest and smallest element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The following functions are available:\n",
    "    \n",
    ">`tf.argmax(input, axis=None, name=None, output_type=tf.int64 )`\n",
    "\n",
    ">`tf.argmin(input, axis=None, name=None, output_type=tf.int64 )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 12  11  51  42   6  16  -8 -19  31], shape=(9,), dtype=int32)\n",
      "index of max;  tf.Tensor(2, shape=(), dtype=int64)\n",
      "Max element:  51\n",
      "index of min:  7\n",
      "Min element:  -19\n"
     ]
    }
   ],
   "source": [
    "# 1-D tensor\n",
    "tensor_1d = tf.constant([12, 11, 51, 42, 6, 16, -8, -19, 31])\n",
    "print(tensor_1d)\n",
    "\n",
    "\n",
    "i = tf.argmax(input=tensor_1d)\n",
    "print('index of max; ', i)\n",
    "print('Max element: ',tensor_1d[i].numpy())\n",
    "\n",
    "\n",
    "i = tf.argmin(input=tensor_1d,axis=0).numpy()\n",
    "print('index of min: ', i)\n",
    "print('Min element: ',tensor_1d[i].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and restoring using a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 4) dtype=int32, numpy=\narray([[ 5,  6,  9,  3],\n       [14, 15, 16, 18]])>\n<tf.Variable 'Variable:0' shape=(2, 4) dtype=int32, numpy=\narray([[0, 0, 0, 0],\n       [0, 0, 0, 0]])>\n<tf.Variable 'Variable:0' shape=(2, 4) dtype=int32, numpy=\narray([[ 5,  6,  9,  3],\n       [14, 15, 16, 18]])>\n"
     ]
    }
   ],
   "source": [
    "variable1 = tf.Variable([[5,6,9,3],[14,15,16,18]])\n",
    "print(variable1)\n",
    "checkpoint= tf.train.Checkpoint(var=variable1)\n",
    "savepath = checkpoint.save('./ckeckpt/vars')\n",
    "variable1.assign([[0,0,0,0],[0,0,0,0]])\n",
    "print(variable1)\n",
    "checkpoint.restore(savepath)\n",
    "print(variable1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using tf.function\n",
    "\n",
    "`tf.function is a function that will take a Python function and return a TensorFlow graph. The advantage of this is that graphs can apply optimizations and exploit parallelism in the Python function (func). tf.function is new to TensorFlow 2.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Its function is as follows:\n",
    "    \n",
    "`tf.function(\n",
    "func=None,input_signature=None,autograph=True,experimental_autograph_options=None\n",
    ")`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, y):\n",
    "    return tf.reduce_mean(input_tensor=tf.multiply(x ** 3, 6) + y**3)\n",
    "func = tf.function(f1)\n",
    "x = tf.constant([3., -4.])\n",
    "y = tf.constant([1., 4.])\n",
    "# f1 and func return the same value, but func executes as a TensorFlow graph\n",
    "assert f1(x,y).numpy() == func(x,y).numpy()\n",
    "#The assert passes, so there is no output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "f1(x,y).numpy() == func(x,y).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=-78.5>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-78.5>)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "f1(x,y),func(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Another difference from numpy is that it can automatically track the gradient of any variable.\n",
    "\n",
    ">Open one GradientTape and `tape.watch()` track variables through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.469929    0.89920384]\n",
      " [-0.66446567 -0.79767007]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(a)\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c,a)\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">For all variables, the calculation is tracked by default and used to find the gradient, so do not use `tape.watch()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.469929    0.89920384]\n",
      " [-0.66446567 -0.79767007]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(a)\n",
    "with tf.GradientTape() as tape:\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c,a)\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can GradientTapefind higher-order derivatives by opening a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.4264985  0.6867533 ]\n",
      " [0.44663432 0.5015956 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as outer_tape:\n",
    "    with tf.GradientTape() as tape:\n",
    "        c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "        dc_da = tape.gradient(c,a)\n",
    "    d2c_d2a = outer_tape.gradient(dc_da,a)\n",
    "    print(d2c_d2a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}