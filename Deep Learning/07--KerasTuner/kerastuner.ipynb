{
 "cells": [
  {
   "source": [
    ">>>>>>>>>   <p style=\"font-size:50px\"><b> Keras Tuner"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Keras Tuner Introduction ::: https://keras-team.github.io/keras-tuner/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n",
    "\n",
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)\n",
    "\n",
    "## Concatenate the Data Frames\n",
    "X=pd.concat([X,geography,gender],axis=1)\n",
    "\n",
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Sanydardization\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    " #####################  OR ##############################\n",
    "\n",
    "def build_model2(hp):\n",
    "    model = keras.Sequential()\n",
    "    n_layers = hp.Int('num_layers', 2, 20)\n",
    "    for i in range(n_layers): # No. of hidden layers\n",
    "        n_neurons = hp.Int('units_'+str(i) ,min_value=32,max_value=512,step=32) # Number of neurons\n",
    "        model.add(layers.Dense(units=n_neurons ,activation='relu', kernel_initializer = 'he_uniform'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid',kernel_initializer = 'glorot_uniform'))\n",
    "\n",
    "    learning_rate_adam =  hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "    optimizer_adam = keras.optimizers.Adam(learning_rate_adam)\n",
    "\n",
    "    model.compile(optimizer=optimizer_adam,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # we can see this in model_history.history.keys(), and when we provide the validation dataset\n",
    "    max_trials=5, # How many cominations to try\n",
    "    executions_per_trial=3, # How many time should the model be trainde for each combination, to reduce the variance in the results\n",
    "    directory='project1',\n",
    "    project_name='Churn')"
   ]
  },
  {
   "source": [
    "`Note: the purpose of having multiple executions per trial is to reduce results variance and therefore be able to more accurately assess the performance of a model. If you want to get results faster, you could set executions_per_trial=1 (single round of training for each model configuration).`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Search space summary\nDefault search space size: 4\nnum_layers (Int)\n{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\nunits_0 (Int)\n{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\nunits_1 (Int)\n{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\nlearning_rate (Choice)\n{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial 5 Complete [00h 00m 25s]\nval_accuracy: 0.8631666501363119\n\nBest val_accuracy So Far: 0.8653333385785421\nTotal elapsed time: 00h 03m 08s\nINFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,epochs=5,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results summary\nResults in project1\\Churn\nShowing 10 best trials\nObjective(name='val_accuracy', direction='max')\nTrial summary\nHyperparameters:\nnum_layers: 15\nunits_0: 512\nunits_1: 448\nlearning_rate: 0.0001\nunits_2: 480\nunits_3: 192\nunits_4: 96\nunits_5: 64\nunits_6: 288\nunits_7: 32\nunits_8: 352\nunits_9: 256\nunits_10: 96\nunits_11: 128\nunits_12: 160\nunits_13: 32\nunits_14: 32\nScore: 0.8653333385785421\nTrial summary\nHyperparameters:\nnum_layers: 6\nunits_0: 160\nunits_1: 64\nlearning_rate: 0.001\nunits_2: 64\nunits_3: 288\nunits_4: 32\nunits_5: 288\nunits_6: 64\nunits_7: 128\nunits_8: 64\nunits_9: 192\nunits_10: 256\nunits_11: 320\nunits_12: 32\nunits_13: 256\nunits_14: 480\nScore: 0.8631666501363119\nTrial summary\nHyperparameters:\nnum_layers: 13\nunits_0: 320\nunits_1: 416\nlearning_rate: 0.001\nunits_2: 256\nunits_3: 160\nunits_4: 416\nunits_5: 320\nunits_6: 160\nunits_7: 448\nunits_8: 96\nunits_9: 32\nunits_10: 32\nunits_11: 32\nunits_12: 32\nScore: 0.862499992052714\nTrial summary\nHyperparameters:\nnum_layers: 12\nunits_0: 480\nunits_1: 416\nlearning_rate: 0.001\nunits_2: 256\nunits_3: 352\nunits_4: 416\nunits_5: 352\nunits_6: 64\nunits_7: 192\nunits_8: 320\nunits_9: 192\nunits_10: 224\nunits_11: 384\nunits_12: 512\nScore: 0.8600000143051147\nTrial summary\nHyperparameters:\nnum_layers: 9\nunits_0: 64\nunits_1: 480\nlearning_rate: 0.0001\nunits_2: 32\nunits_3: 32\nunits_4: 32\nunits_5: 32\nunits_6: 32\nunits_7: 32\nunits_8: 32\nScore: 0.8566666642824808\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<kerastuner.engine.hyperparameters.HyperParameters at 0x1dd68e45248>,\n",
       " <kerastuner.engine.hyperparameters.HyperParameters at 0x1dd73c44cc8>]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "\n",
    "best_hyper = tuner.get_best_hyperparameters(num_trials=2)\n",
    "best_hyper\n",
    "\n",
    "# num_trials: (int, optional). Number of HyperParameters objects to return. \n",
    "# HyperParameters will be returned in sorted order based on trial performance.\n",
    "\n",
    "# Here as we have max_trials = 5. Therefore we have only 5 combinations of hyperparameters that are trained. So even if you put num_trails > 5, it will still return only the trained/tried 5 hyperparameters combination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1dd760c0988>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "best_model = tuner.hypermodel.build(best_hyper[0])\n",
    "# This is to train the model on the best hyper-parameters\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.sequential.Sequential at 0x1dd74d25f48>,\n",
       " <tensorflow.python.keras.engine.sequential.Sequential at 0x1dd715ddec8>]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "tuner.get_best_models(num_models=2)\n",
    "\n",
    "# num_models (int, optional). Number of best models to return. \n",
    "# Models will be returned in sorted order. Defaults to 1.\n",
    "\n",
    "# Returns:\n",
    "# List of trained model instances."
   ]
  },
  {
   "source": [
    "`This method is only a convenience shortcut. For best performance, It is recommended to retrain your Model on the full dataset using the best hyperparameters found during search.`\n",
    "i.e. the best_hyper method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "54/54 [==============================] - 5s 32ms/step - loss: 0.6597 - accuracy: 0.8008 - val_loss: 0.4892 - val_accuracy: 0.7955\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.4797 - accuracy: 0.7842 - val_loss: 0.4369 - val_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.4368 - accuracy: 0.7902 - val_loss: 0.4197 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.3882 - accuracy: 0.7984 - val_loss: 0.3915 - val_accuracy: 0.8376\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.3651 - accuracy: 0.8591 - val_loss: 0.3802 - val_accuracy: 0.8448\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.3473 - accuracy: 0.8655 - val_loss: 0.3737 - val_accuracy: 0.8402\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.3319 - accuracy: 0.8643 - val_loss: 0.3704 - val_accuracy: 0.8463\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.3220 - accuracy: 0.8685 - val_loss: 0.3678 - val_accuracy: 0.8489\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.3203 - accuracy: 0.8673 - val_loss: 0.3656 - val_accuracy: 0.8485\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.3061 - accuracy: 0.8750 - val_loss: 0.3764 - val_accuracy: 0.8531\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.3013 - accuracy: 0.8752 - val_loss: 0.3651 - val_accuracy: 0.8531\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.2791 - accuracy: 0.8884 - val_loss: 0.3732 - val_accuracy: 0.8493\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.2624 - accuracy: 0.8986 - val_loss: 0.3779 - val_accuracy: 0.8459\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.2696 - accuracy: 0.8934 - val_loss: 0.3826 - val_accuracy: 0.8466\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 0.2667 - accuracy: 0.8947 - val_loss: 0.3870 - val_accuracy: 0.8508\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.2576 - accuracy: 0.8969 - val_loss: 0.3936 - val_accuracy: 0.8512\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.2414 - accuracy: 0.9050 - val_loss: 0.3979 - val_accuracy: 0.8489\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 0.2506 - accuracy: 0.9009 - val_loss: 0.4685 - val_accuracy: 0.8285\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.2417 - accuracy: 0.9021 - val_loss: 0.4209 - val_accuracy: 0.8451\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.2308 - accuracy: 0.9057 - val_loss: 0.4438 - val_accuracy: 0.8410\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 2s 28ms/step - loss: 0.2275 - accuracy: 0.9048 - val_loss: 0.4698 - val_accuracy: 0.8364\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.1956 - accuracy: 0.9137 - val_loss: 0.4803 - val_accuracy: 0.8440\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.1927 - accuracy: 0.9165 - val_loss: 0.4892 - val_accuracy: 0.8311\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 1s 27ms/step - loss: 0.2079 - accuracy: 0.9175 - val_loss: 0.5166 - val_accuracy: 0.8368\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.1936 - accuracy: 0.9218 - val_loss: 0.4699 - val_accuracy: 0.8421\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.2135 - accuracy: 0.9139 - val_loss: 0.5096 - val_accuracy: 0.8285\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 0.1606 - accuracy: 0.9323 - val_loss: 0.5659 - val_accuracy: 0.8092\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.1671 - accuracy: 0.9245 - val_loss: 0.5995 - val_accuracy: 0.8213\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1466 - accuracy: 0.9391 - val_loss: 0.5677 - val_accuracy: 0.8209\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1584 - accuracy: 0.9375 - val_loss: 0.5859 - val_accuracy: 0.8383\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1459 - accuracy: 0.9356 - val_loss: 0.6072 - val_accuracy: 0.8103\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1192 - accuracy: 0.9515 - val_loss: 0.6745 - val_accuracy: 0.8145\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.1335 - accuracy: 0.9467 - val_loss: 0.6526 - val_accuracy: 0.8349\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.1125 - accuracy: 0.9524 - val_loss: 0.7565 - val_accuracy: 0.8251\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1082 - accuracy: 0.9582 - val_loss: 0.6460 - val_accuracy: 0.8095\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.0933 - accuracy: 0.9679 - val_loss: 0.8726 - val_accuracy: 0.7955\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.1027 - accuracy: 0.9599 - val_loss: 0.8310 - val_accuracy: 0.8179\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0997 - accuracy: 0.9608 - val_loss: 0.7301 - val_accuracy: 0.8171\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0842 - accuracy: 0.9682 - val_loss: 0.7417 - val_accuracy: 0.8148\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0789 - accuracy: 0.9704 - val_loss: 0.8176 - val_accuracy: 0.8239\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.1162 - accuracy: 0.9543 - val_loss: 0.8552 - val_accuracy: 0.8224\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0558 - accuracy: 0.9789 - val_loss: 0.8996 - val_accuracy: 0.8289\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0681 - accuracy: 0.9750 - val_loss: 1.0767 - val_accuracy: 0.7857\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0735 - accuracy: 0.9691 - val_loss: 0.9512 - val_accuracy: 0.8239\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0641 - accuracy: 0.9728 - val_loss: 1.0624 - val_accuracy: 0.8289\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0545 - accuracy: 0.9789 - val_loss: 1.0817 - val_accuracy: 0.8133\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0639 - accuracy: 0.9747 - val_loss: 1.0467 - val_accuracy: 0.8190\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0648 - accuracy: 0.9755 - val_loss: 1.0912 - val_accuracy: 0.8353\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.0647 - accuracy: 0.9718 - val_loss: 1.0282 - val_accuracy: 0.8039\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.0552 - accuracy: 0.9757 - val_loss: 1.0097 - val_accuracy: 0.8152\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.0462 - accuracy: 0.9815 - val_loss: 1.1842 - val_accuracy: 0.8247\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 1.0707 - val_accuracy: 0.8156\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0417 - accuracy: 0.9843 - val_loss: 1.2338 - val_accuracy: 0.8254\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.0454 - accuracy: 0.9829 - val_loss: 1.2294 - val_accuracy: 0.8016\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0450 - accuracy: 0.9805 - val_loss: 1.2431 - val_accuracy: 0.7944\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 0.0552 - accuracy: 0.9796 - val_loss: 0.9114 - val_accuracy: 0.7967\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 0.0515 - accuracy: 0.9808 - val_loss: 1.2465 - val_accuracy: 0.7899\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0359 - accuracy: 0.9849 - val_loss: 1.2255 - val_accuracy: 0.7940\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 0.0461 - accuracy: 0.9824 - val_loss: 1.1894 - val_accuracy: 0.8205\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0207 - accuracy: 0.9918 - val_loss: 1.4908 - val_accuracy: 0.8137\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 1s 25ms/step - loss: 0.0397 - accuracy: 0.9848 - val_loss: 1.1745 - val_accuracy: 0.8027\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 0.0359 - accuracy: 0.9858 - val_loss: 1.3306 - val_accuracy: 0.8129\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 1.4144 - val_accuracy: 0.8008\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0373 - accuracy: 0.9866 - val_loss: 1.1836 - val_accuracy: 0.8167\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 1.4424 - val_accuracy: 0.8319\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0437 - accuracy: 0.9847 - val_loss: 1.2134 - val_accuracy: 0.7986\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 1.2682 - val_accuracy: 0.8205\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0242 - accuracy: 0.9935 - val_loss: 1.4367 - val_accuracy: 0.8190\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 1.3022 - val_accuracy: 0.8160\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 1.3579 - val_accuracy: 0.8254\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0346 - accuracy: 0.9866 - val_loss: 1.1542 - val_accuracy: 0.8122\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0305 - accuracy: 0.9894 - val_loss: 1.3275 - val_accuracy: 0.8152\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 1.4426 - val_accuracy: 0.8027\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0204 - accuracy: 0.9914 - val_loss: 1.3543 - val_accuracy: 0.8001\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0620 - accuracy: 0.9758 - val_loss: 1.0436 - val_accuracy: 0.8061\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0201 - accuracy: 0.9951 - val_loss: 1.3925 - val_accuracy: 0.8129\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 1.4471 - val_accuracy: 0.8198\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 1.3781 - val_accuracy: 0.8194\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 1.4275 - val_accuracy: 0.8092\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 1.4938 - val_accuracy: 0.8061\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 1.3799 - val_accuracy: 0.8194\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0303 - accuracy: 0.9888 - val_loss: 1.2804 - val_accuracy: 0.8012\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0327 - accuracy: 0.9888 - val_loss: 1.3010 - val_accuracy: 0.8258\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0393 - accuracy: 0.9833 - val_loss: 1.3294 - val_accuracy: 0.8175\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0235 - accuracy: 0.9909 - val_loss: 1.3747 - val_accuracy: 0.8258\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 1.4389 - val_accuracy: 0.8213\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.5479 - val_accuracy: 0.8088\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 1.4575 - val_accuracy: 0.8160\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 1.4341 - val_accuracy: 0.8095\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 1.4952 - val_accuracy: 0.8008\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 1.5076 - val_accuracy: 0.8073\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 1.4828 - val_accuracy: 0.8114\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 1.5800 - val_accuracy: 0.8224\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0314 - accuracy: 0.9891 - val_loss: 1.3363 - val_accuracy: 0.8247\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 1.4772 - val_accuracy: 0.8073\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 0.0162 - accuracy: 0.9931 - val_loss: 1.5485 - val_accuracy: 0.8012\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0303 - accuracy: 0.9898 - val_loss: 1.2308 - val_accuracy: 0.8277\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.0296 - accuracy: 0.9883 - val_loss: 1.3264 - val_accuracy: 0.8239\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 1.5348 - val_accuracy: 0.8217\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 1.5693 - val_accuracy: 0.8224\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd7296b288>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train,validation_split=0.33, batch_size = 100,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 512)               6144      \n_________________________________________________________________\ndense_1 (Dense)              (None, 448)               229824    \n_________________________________________________________________\ndense_2 (Dense)              (None, 480)               215520    \n_________________________________________________________________\ndense_3 (Dense)              (None, 192)               92352     \n_________________________________________________________________\ndense_4 (Dense)              (None, 96)                18528     \n_________________________________________________________________\ndense_5 (Dense)              (None, 64)                6208      \n_________________________________________________________________\ndense_6 (Dense)              (None, 288)               18720     \n_________________________________________________________________\ndense_7 (Dense)              (None, 32)                9248      \n_________________________________________________________________\ndense_8 (Dense)              (None, 352)               11616     \n_________________________________________________________________\ndense_9 (Dense)              (None, 256)               90368     \n_________________________________________________________________\ndense_10 (Dense)             (None, 96)                24672     \n_________________________________________________________________\ndense_11 (Dense)             (None, 128)               12416     \n_________________________________________________________________\ndense_12 (Dense)             (None, 160)               20640     \n_________________________________________________________________\ndense_13 (Dense)             (None, 32)                5152      \n_________________________________________________________________\ndense_14 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_15 (Dense)             (None, 1)                 33        \n=================================================================\nTotal params: 762,497\nTrainable params: 762,497\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}