{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('ml1': conda)",
   "metadata": {
    "interpreter": {
     "hash": "24b04341fb2b46c4dd66e0f21e934c64052be02fe2d7f9a5c55981f8226ca5cf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<p style=\"font-size:32px;text-align:center\"> <b>Social network Graph Link Prediction - Facebook Challenge</b> </p>\n",
    "\n",
    ">>>>>>>>>>>>> # Featurization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "source": [
    "# 1. Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((15100030, 1), (15100030, 2), (3775008, 1), (3775008, 2))"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "X_train = pd.read_csv('datasets/my/xtrain.csv',header=None)\n",
    "Y_train = pd.read_csv('datasets/my/ytrain.csv',header=None)\n",
    "X_test = pd.read_csv('datasets/my/xtest.csv',header=None)\n",
    "Y_test = pd.read_csv('datasets/my/ytest.csv',header=None)\n",
    "Y_train.shape,X_train.shape,Y_test.shape,X_test.shape"
   ]
  },
  {
   "source": [
    "graph created using the positive training data as the negative data consists of unconnected edges which is useless while creating graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg=nx.read_edgelist('datasets/data/after_eda/train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int) "
   ]
  },
  {
   "source": [
    "# 2. Similarity measures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.1 Jaccard Distance:\n",
    "http://www.statisticshowto.com/jaccard-index/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\\begin{equation}\n",
    "j = \\frac{|X\\cap Y|}{|X \\cup Y|} \n",
    "\\end{equation}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.1.1 For Followee (i.e. the source and destination nodes are Followee)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacc_followee(u,v,g):\n",
    "    try:\n",
    "        u_followers  = set([ x for (x,y) in g.in_edges(u)])\n",
    "        v_followers  = set([ x for (x,y) in g.in_edges(v)])\n",
    "        if len(u_followers)==0 | len(v_followers)==0:\n",
    "            return 0\n",
    "        return len(u_followers.intersection(v_followers))/len(u_followers.union(v_followers))\n",
    "    except:\n",
    "        return 0 "
   ]
  },
  {
   "source": [
    "### 2.1.2 For Follower (i.e. the source and destination nodes are Followers)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacc_follower(u,v,g):\n",
    "    try:\n",
    "        u_followees  = set([ y for (x,y) in g.out_edges(u)])\n",
    "        v_followees  = set([ y for (x,y) in g.out_edges(v)])\n",
    "        if len(u_followees)==0 | len(v_followees)==0:\n",
    "            return 0\n",
    "        return len(u_followees.intersection(v_followees))/len(u_followees.union(v_followees))\n",
    "    except:\n",
    "        return 0 "
   ]
  },
  {
   "source": [
    "### 2.1.3 AAI Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for followees\n",
    "# def jaccard_for_followees(a,b):\n",
    "#     try:\n",
    "#         if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "#             return 0\n",
    "#         sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "#                                     (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
    "#     except:\n",
    "#         return 0\n",
    "#     return sim\n",
    "    \n",
    "# #for followers\n",
    "# def jaccard_for_followers(a,b):\n",
    "#     try:\n",
    "#         if len(set(train_graph.predecessors(a))) == 0  | len(set(g.predecessors(b))) == 0:\n",
    "#             return 0\n",
    "#         sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "#                                  (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
    "#         return sim\n",
    "#     except:\n",
    "#         return 0"
   ]
  },
  {
   "source": [
    "## 2.2 Cosine distance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\\begin{equation}\n",
    "CosineDistance = \\frac{|X\\cap Y|}{|X|\\cdot|Y|} \n",
    "\\end{equation}\n",
    "it has an"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u,v being followee\n",
    "def cosine_followee(u,v,g):\n",
    "    try:\n",
    "        u_followers  = set([ x for (x,y) in g.in_edges(u)])\n",
    "        v_followers  = set([ x for (x,y) in g.in_edges(v)])\n",
    "        if len(u_followers)==0 | len(v_followers)==0:\n",
    "            return 0\n",
    "        return len(u_followers.intersection(v_followers))/math.sqrt(len(u_followers)*len(v_followers))\n",
    "    except:\n",
    "        return 0 \n",
    "# u,v being followers\n",
    "def cosine_follower(u,v,g):\n",
    "    try:\n",
    "        u_followees  = set([ y for (x,y) in g.out_edges(u)])\n",
    "        v_followees  = set([ y for (x,y) in g.out_edges(v)])\n",
    "        if len(u_followees)==0 | len(v_followees)==0:\n",
    "            return 0\n",
    "        return len(u_followees.intersection(v_followees))/math.sqrt(len(u_followees)*len(v_followees))\n",
    "    except:\n",
    "        return 0 "
   ]
  },
  {
   "source": [
    "### AAI functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for followees\n",
    "# def cosine_for_followees(a,b):\n",
    "#     try:\n",
    "#         if len(set(tg.successors(a))) == 0  | len(set(tg.successors(b))) == 0:\n",
    "#             return 0\n",
    "#         sim = (len(set(tg.successors(a)).intersection(set(tg.successors(b)))))/\\\n",
    "#                                     (math.sqrt(len(set(tg.successors(a)))*len((set(tg.successors(b))))))    \n",
    "#         return sim\n",
    "#     except:\n",
    "#         return 0\n",
    "\n",
    "# # for followers \n",
    "# def cosine_for_followers(a,b):\n",
    "#     try:\n",
    "        \n",
    "#         if len(set(tg.predecessors(a))) == 0  | len(set(tg.predecessors(b))) == 0:\n",
    "#             return 0\n",
    "#         sim = (len(set(tg.predecessors(a)).intersection(set(tg.predecessors(b)))))/\\\n",
    "#                                      (math.sqrt(len(set(tg.predecessors(a))))*(len(set(tg.predecessors(b)))))\n",
    "#         return sim\n",
    "#     except:\n",
    "#         return 0\n"
   ]
  },
  {
   "source": [
    "## 3. Ranking Measures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html\n",
    "\n",
    "PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links.\n",
    "\n",
    "<img src='PageRanks-Example.jpg' height=300px />\n",
    "\n",
    "Mathematical PageRanks for a simple network, expressed as percentages. (Google uses a logarithmic scale.) Page C has a higher PageRank than Page E, even though there are fewer links to C; the one link to C comes from an important page and hence is of high value. If web surfers who start on a random page have an 85% likelihood of choosing a random link from the page they are currently visiting, and a 15% likelihood of jumping to a page chosen at random from the entire web, they will reach Page E 8.1% of the time. <b>(The 15% likelihood of jumping to an arbitrary page corresponds to a damping factor of 85%.) Without damping, all web surfers would eventually end up on Pages A, B, or C, and all other pages would have PageRank zero. In the presence of damping, Page A effectively links to all pages in the web, even though it has no outgoing links of its own.</b>\n",
    "\n",
    "https://en.wikipedia.org/wiki/PageRank"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### ` page rank is fairly based on complex graph theory, so we are not going to go deep here about various aspects of pagerank like 'alhpa value' etc.` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('datasets/pickle/page_rank.p'):\n",
    "    pr = nx.pagerank(tg, alpha=0.85)\n",
    "    pickle.dump(pr,open('datasets/pickle/page_rank.p','wb'))\n",
    "else:\n",
    "    pr = pickle.load(open('datasets/pickle/page_rank.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "type(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "min 1.6556497245737814e-07\nmax 2.7098251341935827e-05\nmean 5.615699699389075e-07\n"
     ]
    }
   ],
   "source": [
    "print('min',min(list(pr.values())))\n",
    "print('max',max(list(pr.values())))\n",
    "print('mean',float(sum(pr.values())) / len(pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5.615699699389075e-07\n"
     ]
    }
   ],
   "source": [
    "#for imputing to nodes which are not there in Train data\n",
    "mean_pr = float(sum(pr.values())) / len(pr)\n",
    "print(mean_pr)"
   ]
  },
  {
   "source": [
    " # 4. Other Graph Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.1 Shortest path:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Getting Shortest path between twoo nodes, if nodes have direct path i.e directly connected then we are removing that edge and calculating path. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(u,v,g):\n",
    "    try:\n",
    "        if not nx.has_path(g,u,v):\n",
    "            return -1\n",
    "        elif g.has_edge(u,v):\n",
    "            g.remove_edge(u,v)\n",
    "            p = nx.shortest_path_length(g,source=u,target=v)\n",
    "            g.add_edge(u,v)\n",
    "            return p\n",
    "        else:\n",
    "            return nx.shortest_path_length(g,source=u,target=v)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "source": [
    "## 4.2 Checking for same community"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting weekly connected edges from graph \n",
    "wcc=list(nx.weakly_connected_components(tg))\n",
    "def same_wcc(u,v):\n",
    "    index = []\n",
    "    if tg.has_edge(v,u):\n",
    "        return 1\n",
    "    if tg.has_edge(u,v):\n",
    "            for i in wcc:\n",
    "                if u in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if (v in index):\n",
    "                tg.remove_edge(u,v)\n",
    "                if shortest_path(u,v,tg)==-1:\n",
    "                    tg.add_edge(u,v)\n",
    "                    return 0\n",
    "                else:\n",
    "                    tg.add_edge(u,v)\n",
    "                    return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "            for i in wcc:\n",
    "                if u in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if(v in index):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "source": [
    "## 4.3 Adamic/Adar Index:\n",
    "Adamic/Adar measures is defined as inverted sum of degrees of common neighbours for given two vertices.\n",
    "$$A(x,y)=\\sum_{u \\in N(x) \\cap N(y)}\\frac{1}{log(|N(u)|)}$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adar index\n",
    "def adar_index(u,v):\n",
    "    sum=0\n",
    "    try:\n",
    "        n=list(set(tg.successors(u)).intersection(set(tg.successors(v))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(tg.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "source": [
    "## 4.4 Is persion was following back:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def follow_back(u,v):\n",
    "    try:\n",
    "        if tg.has_edge(v,u):\n",
    "            return 1\n",
    "        else: \n",
    "            return 0 \n",
    "    except:\n",
    "        return 0 "
   ]
  },
  {
   "source": [
    "## 4.5 Katz Centrality:\n",
    "https://en.wikipedia.org/wiki/Katz_centrality\n",
    "\n",
    "https://www.geeksforgeeks.org/katz-centrality-centrality-measure/\n",
    " Katz centrality computes the centrality for a node \n",
    "    based on the centrality of its neighbors. It is a \n",
    "    generalization of the eigenvector centrality. The\n",
    "    Katz centrality for node `i` is\n",
    " \n",
    "$$x_i = \\alpha \\sum_{j} A_{ij} x_j + \\beta,$$\n",
    "where `A` is the adjacency matrix of the graph G \n",
    "with eigenvalues $$\\lambda$$.\n",
    "\n",
    "The parameter $$\\beta$$ controls the initial centrality and \n",
    "\n",
    "$$\\alpha < \\frac{1}{\\lambda_{max}}.$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "min 0.0007313532484065916\nmax 0.003394554981699122\n0.0007483800935562018\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('datasets/pickle/katz.p'):\n",
    "    katz = nx.katz.katz_centrality(tg,alpha=0.005,beta=1)\n",
    "    pickle.dump(katz,open('datasets/pickle/katz.p','wb'))\n",
    "else:\n",
    "    katz = pickle.load(open('datasets/pickle/katz.p','rb'))\n",
    "\n",
    "print('min',katz[min(katz, key=katz.get)])\n",
    "print('max',katz[max(katz, key=katz.get)])\n",
    "# print('mean',float(sum(katz.values())) / len(katz))\n",
    "\n",
    "mean_katz = float(sum(katz.values())) / len(katz)\n",
    "print(mean_katz)"
   ]
  },
  {
   "source": [
    "## 4.6 Hits Score\n",
    "The HITS algorithm computes two numbers for a node. Authorities estimates the node value based on the incoming links. Hubs estimates the node value based on outgoing links.\n",
    "\n",
    "https://en.wikipedia.org/wiki/HITS_algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "min 0.0\nmax 0.004868653378780953\nmean 5.615699699344123e-07\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('datasets/pickle/hits.p'):\n",
    "    hits = nx.hits(tg, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
    "    pickle.dump(hits,open('datasets/pickle/hits.p','wb'))\n",
    "else:\n",
    "    hits = pickle.load(open('datasets/pickle/hits.p','rb'))\n",
    "\n",
    "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
    "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
    "print('mean',float(sum(hits[0].values())) / len(hits[0]))"
   ]
  },
  {
   "source": [
    "# 5. Featurization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5. 1 Reading a sample of Data from both train and test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['y'] = Y_train.astype('int32')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0        1  y\n",
       "0   273084  1505602  1\n",
       "1   912810  1678443  1\n",
       "2   365429  1523458  1\n",
       "3   527014  1605979  1\n",
       "4  1228116   471233  1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>273084</td>\n      <td>1505602</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>912810</td>\n      <td>1678443</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>365429</td>\n      <td>1523458</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>527014</td>\n      <td>1605979</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1228116</td>\n      <td>471233</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['y'] = Y_test.astype('int32')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0        1  y\n",
       "0   848424   784690  1\n",
       "1  1248963   444518  1\n",
       "2   264224   132395  1\n",
       "3   549680   326829  1\n",
       "4   875380  1394902  1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>848424</td>\n      <td>784690</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1248963</td>\n      <td>444518</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>264224</td>\n      <td>132395</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>549680</td>\n      <td>326829</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875380</td>\n      <td>1394902</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "X_test.head(5)"
   ]
  },
  {
   "source": [
    "### Sampling form the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((50092, 3), (49908, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "xtrain = X_train.sample(n = 100000,replace = False,random_state = 2)\n",
    "xtrain[xtrain['y']==0].shape,xtrain[xtrain['y']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((24971, 3), (25029, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "xtest = X_test.sample(n = 50000,replace = False,random_state = 2)\n",
    "xtest[xtest['y']==0].shape,xtest[xtest['y']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                0        1  y\n",
       "1978364    488489  1053487  1\n",
       "7556568   1248019   995936  0\n",
       "2708232   1166276   431589  1\n",
       "13693456  1707801   977540  0\n",
       "10614818   168329   615541  0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1978364</th>\n      <td>488489</td>\n      <td>1053487</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7556568</th>\n      <td>1248019</td>\n      <td>995936</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2708232</th>\n      <td>1166276</td>\n      <td>431589</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13693456</th>\n      <td>1707801</td>\n      <td>977540</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10614818</th>\n      <td>168329</td>\n      <td>615541</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "xtrain.head(5)"
   ]
  },
  {
   "source": [
    "## 5.2 Adding a set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>jaccard_followers</li>\n",
    "<li>jaccard_followees</li>\n",
    "<li>cosine_followers</li>\n",
    "<li>cosine_followees</li>\n",
    "<li>num_followers_s</li>\n",
    "<li>num_followees_s</li>\n",
    "<li>num_followers_d</li>\n",
    "<li>num_followees_d</li>\n",
    "<li>inter_followers</li>\n",
    "<li>inter_followees</li>\n",
    "</ol>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Faeture 1,2,3,4\n",
    "\n",
    "xtrain['jacc_followee']  = xtrain.apply(lambda x:jacc_followee(x[0],x[1],tg),axis=1)\n",
    "xtrain['jacc_follower']  = xtrain.apply(lambda x:jacc_follower(x[0],x[1],tg),axis=1)\n",
    "xtrain['cosine_followee']  = xtrain.apply(lambda x:cosine_followee(x[0],x[1],tg),axis=1)\n",
    "xtrain['cosine_follower']  = xtrain.apply(lambda x:cosine_follower(x[0],x[1],tg),axis=1)\n",
    "\n",
    "xtest['jacc_followee']  = xtest.apply(lambda x:jacc_followee(x[0],x[1],tg),axis=1)\n",
    "xtest['jacc_follower']  = xtest.apply(lambda x:jacc_follower(x[0],x[1],tg),axis=1)\n",
    "xtest['cosine_followee']  = xtest.apply(lambda x:cosine_followee(x[0],x[1],tg),axis=1)\n",
    "xtest['cosine_follower']  = xtest.apply(lambda x:cosine_follower(x[0],x[1],tg),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 5 i.e no. of followers of the u\n",
    "def foller(n):\n",
    "    try:\n",
    "        return len(set(tg.predecessors(n)))\n",
    "    except:\n",
    "        return 0 \n",
    "xtrain['num_followers_s'] = xtrain.apply(lambda x:foller(x[0]),axis=1)\n",
    "xtest['num_followers_s'] = xtest.apply(lambda x:foller(x[0]),axis=1)\n",
    "\n",
    "# feature 7 i.e no. of followers of the v\n",
    "xtrain['num_followers_d'] = xtrain.apply(lambda x:foller(x[1]),axis=1)\n",
    "xtest['num_followers_d'] = xtest.apply(lambda x:foller(x[1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 6 and 8 i.e no of nodes u,v follow\n",
    "def folloee(n):\n",
    "    try:\n",
    "        return len(set(tg.successors(n)))\n",
    "    except:\n",
    "        return 0 \n",
    "xtrain['num_followees_s'] = xtrain.apply(lambda x:folloee(x[0]),axis=1)\n",
    "xtest['num_followees_s'] = xtest.apply(lambda x:folloee(x[0]),axis=1)\n",
    "\n",
    "xtrain['num_followees_d'] = xtrain.apply(lambda x:folloee(x[1]),axis=1)\n",
    "xtest['num_followees_d'] = xtest.apply(lambda x:folloee(x[1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 9\n",
    "def intre_follower(u,v):\n",
    "    try:\n",
    "        return len(set(tg.predecessors(u)).intersection(set(tg.predecessors(v))))\n",
    "    except:\n",
    "        return 0\n",
    "xtrain['inter_followers'] = xtrain.apply(lambda x:intre_follower(x[0],x[1]),axis=1)\n",
    "xtest['inter_followers'] = xtest.apply(lambda x:intre_follower(x[0],x[1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 10\n",
    "def intre_followee(u,v):\n",
    "    try:\n",
    "        return len(set(tg.successors(u)).intersection(set(tg.successors(v))))\n",
    "    except:\n",
    "        return 0\n",
    "xtrain['inter_followees'] = xtrain.apply(lambda x:intre_followee(x[0],x[1]),axis=1)\n",
    "xtest['inter_followees'] = xtest.apply(lambda x:intre_followee(x[0],x[1]),axis=1)"
   ]
  },
  {
   "source": [
    "## 5.3 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>adar index</li>\n",
    "<li>is following back</li>\n",
    "<li>belongs to same weakly connect components</li>\n",
    "<li>shortest path between source and destination</li>\n",
    "</ol>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 1\n",
    "xtrain['adar_index'] = xtrain.apply(lambda x:adar_index(x[0],x[1]),axis=1)\n",
    "xtest['adar_index'] = xtest.apply(lambda x:adar_index(x[0],x[1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 2\n",
    "xtrain['follow_back'] = xtrain.apply(lambda x:follow_back(x[0],x[1]),axis=1)\n",
    "xtest['follow_back'] = xtest.apply(lambda x:follow_back(x[0],x[1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 3\n",
    "xtrain['same_wcc'] = xtrain.apply(lambda x:same_wcc(x[0],x[1]),axis=1)\n",
    "xtest['same_wcc'] = xtest.apply(lambda x:same_wcc(x[0],x[1]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 4\n",
    "xtrain['shortest_path'] = xtrain.apply(lambda x:shortest_path(x[0],x[1],tg),axis=1)\n",
    "xtest['shortest_path'] = xtest.apply(lambda x:shortest_path(x[0],x[1],tg),axis=1)"
   ]
  },
  {
   "source": [
    "## 5.4 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>Weight Features\n",
    "    <ul>\n",
    "        <li>weight of incoming edges</li>\n",
    "        <li>weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges + weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges * weight of outgoing edges</li>\n",
    "        <li>2*weight of incoming edges + weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges + 2*weight of outgoing edges</li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li>Page Ranking of source</li>\n",
    "<li>Page Ranking of dest</li>\n",
    "<li>katz of source</li>\n",
    "<li>katz of dest</li>\n",
    "<li>hubs of source</li>\n",
    "<li>hubs of dest</li>\n",
    "<li>authorities_s of source</li>\n",
    "<li>authorities_s of dest</li>\n",
    "</ol>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Weight Features\n",
    "In order to determine the similarity of nodes, an edge weight value was calculated between nodes. Edge weight decreases as the neighbor count goes up. Intuitively, consider one million people following a celebrity on a social network then chances are most of them never met each other or the celebrity. On the other hand, if a user has 30 contacts in his/her social network, the chances are higher that many of them know each other. \n",
    "`credit` - Graph-based Features for Supervised Link Prediction\n",
    "William Cukierski, Benjamin Hamner, Bo Yang\n",
    "\n",
    "\\begin{equation}\n",
    "W = \\frac{1}{\\sqrt{1+|X|}}\n",
    "\\end{equation}\n",
    "\n",
    "it is directed graph so calculated Weighted in and Weighted out differently"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1780722/1780722 [00:48<00:00, 37065.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#weight for source and destination of each link\n",
    "Weight_in = {}\n",
    "Weight_out = {}\n",
    "for i in  tqdm(tg.nodes()):\n",
    "    s1=set(tg.predecessors(i))\n",
    "    w_in = 1.0/(np.sqrt(1+len(s1)))\n",
    "    Weight_in[i]=w_in\n",
    "    \n",
    "    s2=set(tg.successors(i))\n",
    "    w_out = 1.0/(np.sqrt(1+len(s2)))\n",
    "    Weight_out[i]=w_out\n",
    "    \n",
    "#for imputing with mean\n",
    "mean_weight_in = np.mean(list(Weight_in.values()))\n",
    "mean_weight_out = np.mean(list(Weight_out.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1\n",
    "def weight_features(u,v):\n",
    "    one = Weight_in.get(u,mean_weight_in)\n",
    "    two = Weight_out.get(v,mean_weight_out)\n",
    "    three = one + two\n",
    "    four = one * two\n",
    "    five = (2*one)+two\n",
    "    six = one+(two*2)\n",
    "    return one,two,three,four,five,six\n",
    "xtrain['wt_1'],xtrain['wt_2'],xtrain['wt_3'],xtrain['wt_4'],xtrain['wt_5'],xtrain['wt_6'] = zip(*xtrain.apply(lambda x: weight_features(x[0],x[1]),axis=1))\n",
    "xtest['wt_1'],xtest['wt_2'],xtest['wt_3'],xtest['wt_4'],xtest['wt_5'],xtest['wt_6'] = zip(*xtest.apply(lambda x: weight_features(x[0],x[1]),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature 2\n",
    "xtrain['pagerank_s'] = xtrain[0].apply(lambda x: pr.get(x,mean_pr))\n",
    "xtest['pagerank_s'] = xtest[0].apply(lambda x: pr.get(x,mean_pr))\n",
    "\n",
    "#Feature 3\n",
    "xtrain['pagerank_d'] = xtrain[1].apply(lambda x: pr.get(x,mean_pr))\n",
    "xtest['pagerank_d'] = xtest[1].apply(lambda x: pr.get(x,mean_pr))\n",
    "\n",
    "#Freature 4\n",
    "xtrain['katz_s'] = xtrain[0].apply(lambda x: katz.get(x,mean_katz))\n",
    "xtest['katz_s'] = xtest[0].apply(lambda x: katz.get(x,mean_katz))\n",
    "\n",
    "#Feature 5Adj = nx.adjacency_matrix(train_graph,nodelist=sorted(train_graph.nodes())).asfptype()\n",
    "xtrain['katz_d'] = xtrain[1].apply(lambda x: katz.get(x,mean_katz))\n",
    "xtest['katz_d'] = xtest[1].apply(lambda x: katz.get(x,mean_katz))\n",
    "\n",
    "#Feature 6\n",
    "xtrain['hubs_s'] = xtrain[0].apply(lambda x: hits[0].get(x,0))\n",
    "xtest['hubs_s'] = xtest[0].apply(lambda x: hits[0].get(x,0))\n",
    "\n",
    "#Feature 7\n",
    "xtrain['hubs_d'] = xtrain[1].apply(lambda x: hits[0].get(x,0))\n",
    "xtest['hubs_d'] = xtest[1].apply(lambda x: hits[0].get(x,0))\n",
    "\n",
    "#Feature 9\n",
    "xtrain['authorities_s'] = xtrain[0].apply(lambda x: hits[1].get(x,0))\n",
    "xtest['authorities_s'] = xtest[0].apply(lambda x: hits[1].get(x,0))\n",
    "\n",
    "#Feature 10\n",
    "xtrain['authorities_d'] = xtrain[1].apply(lambda x: hits[1].get(x,0))\n",
    "xtest['authorities_d'] = xtest[1].apply(lambda x: hits[1].get(x,0))"
   ]
  },
  {
   "source": [
    "## 5.5 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>SVD features for both source and destination</li>\n",
    "</ol>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adj = nx.adjacency_matrix(tg,nodelist=sorted(tg.nodes())).asfptype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adjacency matrix Shape (1780722, 1780722)\nU Shape (1780722, 6)\nV Shape (6, 1780722)\ns Shape (6,)\n"
     ]
    }
   ],
   "source": [
    "U, s, V = svds(Adj, k = 6) \n",
    "print('Adjacency matrix Shape',Adj.shape)\n",
    "print('U Shape',U.shape)\n",
    "print('V Shape',V.shape)\n",
    "print('s Shape',s.shape)"
   ]
  },
  {
   "source": [
    "We have got two feature sets i.e U & V\n",
    "Since K=6 each node say source will have an 6 dimentional U feature and then same with V. Similarly the destination node will have 6 n 6 dimentional feature.\n",
    "Therefore we will have new 6*4=24 dimentional feature."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "When we make use of svds of scipy we get U,V. But now we no longer have the names of the nodes. So we need to first stored the nodes with it's index so that we can get the index of U/V when we have the value/no. of an particulat node.\n",
    "'''\n",
    "def svd(x, S):\n",
    "    try:\n",
    "        z = sadj_dict[x]\n",
    "        return S[z]\n",
    "    except:\n",
    "        return [0,0,0,0,0,0]\n",
    "\n",
    "#for svd features to get feature vector creating a dict node val and inedx in svd vector\n",
    "sadj_col = sorted(tg.nodes())\n",
    "sadj_dict = { val:idx for idx,val in enumerate(sadj_col)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain['svd_u_s_1'],xtrain['svd_u_s_2'],xtrain['svd_u_s_3'],xtrain['svd_u_s_4'],xtrain['svd_u_s_5'],xtrain['svd_u_s_6'] = zip(*xtrain[0].apply(lambda x : svd(x,U)))\n",
    "xtest['svd_u_s_1'],xtest['svd_u_s_2'],xtest['svd_u_s_3'],xtest['svd_u_s_4'],xtest['svd_u_s_5'],xtest['svd_u_s_6'] = zip(*xtest[0].apply(lambda x : svd(x,U)))\n",
    "\n",
    "xtrain['svd_u_d_1'],xtrain['svd_u_d_2'],xtrain['svd_u_d_3'],xtrain['svd_u_d_4'],xtrain['svd_u_d_5'],xtrain['svd_u_d_6'] = zip(*xtrain[1].apply(lambda x : svd(x,U)))\n",
    "xtest['svd_u_d_1'],xtest['svd_u_d_2'],xtest['svd_u_d_3'],xtest['svd_u_d_4'],xtest['svd_u_d_5'],xtest['svd_u_d_6'] = zip(*xtest[1].apply(lambda x : svd(x,U)))\n",
    "\n",
    "xtrain['svd_v_s_1'],xtrain['svd_v_s_2'],xtrain['svd_v_s_3'],xtrain['svd_v_s_4'],xtrain['svd_v_s_5'],xtrain['svd_v_s_6'] = zip(*xtrain[0].apply(lambda x : svd(x,V.T)))\n",
    "xtest['svd_v_s_1'],xtest['svd_v_s_2'],xtest['svd_v_s_3'],xtest['svd_v_s_4'],xtest['svd_v_s_5'],xtest['svd_v_s_6'] = zip(*xtest[0].apply(lambda x : svd(x,V.T)))\n",
    "\n",
    "xtrain['svd_v_d_1'],xtrain['svd_v_d_2'],xtrain['svd_v_d_3'],xtrain['svd_v_d_4'],xtrain['svd_v_d_5'],xtrain['svd_v_d_6'] = zip(*xtrain[1].apply(lambda x : svd(x,V.T)))\n",
    "xtest['svd_v_d_1'],xtest['svd_v_d_2'],xtest['svd_v_d_3'],xtest['svd_v_d_4'],xtest['svd_v_d_5'],xtest['svd_v_d_6'] = zip(*xtest[1].apply(lambda x : svd(x,V.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index([                0,                 1,               'y',\n",
       "         'jacc_followee',   'jacc_follower', 'cosine_followee',\n",
       "       'cosine_follower', 'num_followers_s', 'num_followers_d',\n",
       "       'num_followees_s', 'num_followees_d', 'inter_followers',\n",
       "       'inter_followees',      'adar_index',     'follow_back',\n",
       "              'same_wcc',            'wt_1',            'wt_2',\n",
       "                  'wt_3',            'wt_4',            'wt_5',\n",
       "                  'wt_6',      'pagerank_s',      'pagerank_d',\n",
       "                'katz_s',          'katz_d',          'hubs_s',\n",
       "                'hubs_d',   'authorities_s',   'authorities_d',\n",
       "             'svd_u_s_1',       'svd_u_s_2',       'svd_u_s_3',\n",
       "             'svd_u_s_4',       'svd_u_s_5',       'svd_u_s_6',\n",
       "             'svd_u_d_1',       'svd_u_d_2',       'svd_u_d_3',\n",
       "             'svd_u_d_4',       'svd_u_d_5',       'svd_u_d_6',\n",
       "             'svd_v_s_1',       'svd_v_s_2',       'svd_v_s_3',\n",
       "             'svd_v_s_4',       'svd_v_s_5',       'svd_v_s_6',\n",
       "             'svd_v_d_1',       'svd_v_d_2',       'svd_v_d_3',\n",
       "             'svd_v_d_4',       'svd_v_d_5',       'svd_v_d_6',\n",
       "         'shortest_path'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index([                0,                 1,               'y',\n",
       "         'jacc_followee',   'jacc_follower', 'cosine_followee',\n",
       "       'cosine_follower', 'num_followers_s', 'num_followers_d',\n",
       "       'num_followees_s', 'num_followees_d', 'inter_followers',\n",
       "       'inter_followees',      'adar_index',     'follow_back',\n",
       "              'same_wcc',            'wt_1',            'wt_2',\n",
       "                  'wt_3',            'wt_4',            'wt_5',\n",
       "                  'wt_6',      'pagerank_s',      'pagerank_d',\n",
       "                'katz_s',          'katz_d',          'hubs_s',\n",
       "                'hubs_d',   'authorities_s',   'authorities_d',\n",
       "             'svd_u_s_1',       'svd_u_s_2',       'svd_u_s_3',\n",
       "             'svd_u_s_4',       'svd_u_s_5',       'svd_u_s_6',\n",
       "             'svd_u_d_1',       'svd_u_d_2',       'svd_u_d_3',\n",
       "             'svd_u_d_4',       'svd_u_d_5',       'svd_u_d_6',\n",
       "             'svd_v_s_1',       'svd_v_s_2',       'svd_v_s_3',\n",
       "             'svd_v_s_4',       'svd_v_s_5',       'svd_v_s_6',\n",
       "             'svd_v_d_1',       'svd_v_d_2',       'svd_v_d_3',\n",
       "             'svd_v_d_4',       'svd_v_d_5',       'svd_v_d_6',\n",
       "         'shortest_path'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "xtest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.to_csv('datasets/my/featured_train.csv')\n",
    "xtest.to_csv('datasets/my/featured_test.csv')"
   ]
  },
  {
   "source": [
    "# Extra Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "1. Add another feature called  Preferential Attachment  with followers and followees data of vertex. you can check about Preferential Attachment in below link\n",
    "http://be.amazd.com/link-prediction/ <br>\n",
    "2. Add  feature called svd_dot. you can calculate svd_dot as Dot product between sourse node svd and destination node svd features.  you can read about this in below pdf \n",
    "https://storage.googleapis.com/kaggle-forum-message-attachments/2594/supervised_link_prediction.pdf<br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}